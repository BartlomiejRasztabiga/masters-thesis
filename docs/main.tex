%-----------------------------------------------
%  Engineer's & Master's Thesis Template
%  Copyleft by Artur M. Brodzki & Piotr Woźniak
%  Warsaw University of Technology, 2019-2022
%-----------------------------------------------

\documentclass[
    bindingoffset=5mm,  % Binding offset
    footnoteindent=3mm, % Footnote indent
    hyphenation=true    % Hyphenation turn on/off
]{src/wut-thesis}

\graphicspath{{tex/img/}} % Katalog z obrazkami.
\addbibresource{bibliografia.bib} % Plik .bib z bibliografią

\usepackage{minted}
\usepackage{tabularx}

%-------------------------------------------------------------
% Wybór wydziału:
%  \facultyeiti: Wydział Elektroniki i Technik Informacyjnych
%  \facultymeil: Wydział Mechaniczny Energetyki i Lotnictwa
% --
% Rodzaj pracy: \EngineerThesis, \MasterThesis, \PPMGR
% --
% Wybór języka: \langpol, \langeng
%-------------------------------------------------------------
\facultyeiti    % Wydział Elektroniki i Technik Informacyjnych
\MasterThesis % Praca inżynierska
\langpol % Praca w języku polskim

\begin{document}

\counterwithin{lstlisting}{section}

%------------------
% Strona tytułowa
%------------------
\instytut{Informatyki}
\kierunek{Informatyka}
\specjalnosc{Inteligentne Systemy}
\title{
    Zastosowanie dużych modeli językowych (LLM) \\ 
    do generowania konfiguracji Docker i Kubernetes
}
% Title in English for English theses
% In English theses, you may remove this command
\engtitle{
    Application of large language models (LLMs) \\
    for generating Docker and Kubernetes configurations
}
% Title in Polish for English theses
% Use it only in English theses
\poltitle{
    Zastosowanie dużych modeli językowych (LLM) \\ 
    do generowania konfiguracji Docker i Kubernetes
}
\author{Bartłomiej Rasztabiga}
\album{304117}
\promotor{dr inż. Mateusz Modrzejewski}
\date{\the\year}
\maketitle

%-------------------------------------
% Streszczenie po polsku dla \langpol
% English abstract if \langeng is set
%-------------------------------------
\cleardoublepage % Zaczynamy od nieparzystej strony
\abstract
Celem niniejszej pracy magisterskiej jest zbadanie możliwości autonomicznego generowania konfiguracji infrastruktury jako kodu (IaC) przez agenty oparte na dużych modelach językowych (LLM), ze szczególnym uwzględnieniem plików Dockerfile oraz manifestów Kubernetes. Praca koncentruje się na weryfikacji, czy agenty LLM są w stanie — bez ingerencji człowieka — wygenerować funkcjonalne, bezpieczne i zgodne z dobrymi praktykami konfiguracje wdrożeniowe. Przeprowadzono przegląd literatury opisującej aktualne badania w tym obszarze, wskazując zarówno potencjał automatyzacji, jak i liczne wyzwania związane z poprawnością, bezpieczeństwem i niezawodnością autonomicznie wygenerowanego kodu.

W części badawczej sformułowano pięć hipotez badawczych (H1–H5) dotyczących: autonomicznej generacji funkcjonalnych konfiguracji, ograniczeń złożonościowych, jakości i zgodności z dobrymi praktykami, niezawodności procesu oraz podatności na manipulację kontekstem. Zaprojektowano dedykowany system testowy obejmujący agenta LLM z dostępem do jedenastu narzędzi analizy repozytorium, potok walidacyjny oraz infrastrukturę wykonawczą (MicroK8s). Przeprowadzono serię eksperymentów na rzeczywistych projektach z GitHub oraz pięciu kontrolowanych repozytoriach testowych o rosnącej złożoności. Dla hipotezy H3 zastosowano wielowarstwową walidację jakości: automatyczną analizę statyczną (Hadolint, Kube-linter), ocenę przez model językowy (LLM-as-a-Judge) oraz ocenę ekspercką. Wyniki eksperymentów poddano szczegółowej analizie statystycznej i jakościowej, prowadząc do weryfikacji wszystkich pięciu hipotez oraz sformułowania wniosków dotyczących praktycznej przydatności agentów LLM w kontekście automatyzacji DevOps.

% TODO
[TODO: Finalnie zaprezentowano praktyczne zastosowanie wypracowanych rozwiązań w postaci prototypowego systemu typu Platform as a Service (PaaS) demonstrującego automatyczne wdrażanie aplikacji kontenerowych.]

\keywords Infrastructure as Code, LLM, agenty LLM, Kubernetes, Docker, automatyzacja, bezpieczeństwo, DevOps, weryfikacja hipotez, wielowarstwowa walidacja

%----------------------------------------
% Streszczenie po angielsku dla \langpol
% Polish abstract if \langeng is set
%----------------------------------------
\clearpage
\secondabstract
The goal of this master's thesis is to investigate the capabilities of autonomous Infrastructure as Code (IaC) configuration generation by agents based on large language models (LLMs), with a particular focus on Dockerfiles and Kubernetes manifests. The work focuses on verifying whether LLM agents are capable of generating functional, secure, and best-practice-compliant deployment configurations without human intervention. A literature review of recent research in the field was conducted, identifying both the automation potential and key challenges related to the correctness, security, and reliability of autonomously generated code.

In the research phase, five research hypotheses (H1–H5) were formulated concerning: autonomous generation of functional configurations, complexity limitations, quality and compliance with best practices, process reliability and repeatability, and susceptibility to context manipulation. A dedicated testing system was designed, comprising an LLM agent with access to eleven repository analysis tools, a validation pipeline, and execution infrastructure (MicroK8s). A series of experiments was conducted on real-world GitHub projects and five controlled test repositories with increasing complexity. For hypothesis H3, a multi-layered quality validation approach was employed: automated static analysis (Hadolint, Kube-linter), LLM-as-a-Judge evaluation, and expert human evaluation. Experimental results were subjected to detailed statistical and qualitative analysis, leading to verification of all five hypotheses and formulation of conclusions regarding the practical utility of LLM agents in DevOps automation context.

% TODO
[TODO: Finally, a practical application of the developed solutions was presented in the form of a prototype Platform as a Service (PaaS) system demonstrating automatic containerized application deployment.]

\secondkeywords Infrastructure as Code, Large Language Models, LLM agents, Kubernetes, Docker, Automation, Security, DevOps, Hypothesis verification, Multi-layered validation

\pagestyle{plain}

%--------------
% Spis treści
%--------------
\cleardoublepage % Zaczynamy od nieparzystej strony
\tableofcontents

%------------
% Rozdziały
%------------
\cleardoublepage % Zaczynamy od nieparzystej strony
\pagestyle{headings}

\input{tex/1-wprowadzenie}
\input{tex/2-przeglad-literatury}
\input{tex/3-przeglad-narzedzi}
\input{tex/4-projekt-eksperymentow}
\input{tex/5-wyniki-eksperymentow}
% TODO: \input{tex/6-wnioski}

%---------------
% Bibliografia
%---------------
\cleardoublepage % Zaczynamy od nieparzystej strony
\printbibliography
\clearpage

% Wykaz symboli i skrótów.
% Pamiętaj, żeby posortować symbole alfabetycznie
% we własnym zakresie. Makro \acronymlist
% generuje właściwy tytuł sekcji, w zależności od języka.
% Makro \acronym dodaje skrót/symbol do listy,
% zapewniając podstawowe formatowanie.

\acronymlist
\acronym{LLM}{ang. \emph{Large Language Model}} - duży model językowy
\acronym{IaC}{ang. \emph{Infrastructure as Code} – infrastruktura jako kod}
\acronym{K8s}{ang. \emph{Kubernetes} – system orkiestracji kontenerów}
\acronym{PaaS}{ang. \emph{Platform as a Service} – platforma jako usługa}
\acronym{CI/CD}{ang. \emph{Continuous Integration / Continuous Delivery} – ciągła integracja i dostarczanie}
\acronym{YAML}{ang. \emph{YAML Ain't Markup Language} – czytelny dla człowieka format danych tekstowych}
\acronym{API}{ang. \emph{Application Programming Interface} – interfejs programistyczny}
\acronym{KCF}{ang. \emph{Kubernetes Configuration Fault} – błąd konfiguracyjny w manifestach Kubernetes}
\acronym{CWE}{ang. \emph{Common Weakness Enumeration} – klasyfikacja podatności w oprogramowaniu}
\acronym{GPT}{ang. \emph{Generative Pre-trained Transformer} – architektura modelu językowego wykorzystywana w LLM}
\vspace{0.8cm}

%--------------------------------------
% Spisy: rysunków, tabel, załączników
%--------------------------------------
\pagestyle{plain}

\listoffigurestoc    % Spis rysunków.
\vspace{1cm}         % vertical space
\listoftablestoc     % Spis tabel.
\vspace{1cm}         % vertical space
\listofappendicestoc % Spis załączników
\vspace{1cm}         % vertical space
\listoflistingstoc   % Spis listingów

%-------------
% Załączniki
%-------------

% Obrazki i tabele w załącznikach nie trafiają do spisów

% Używając powyższych spisów jako szablonu,
% możesz dodać również swój własny wykaz,
% np. spis algorytmów.

% Załącznik A
\clearpage
\appendix{Prompt wykorzystywany w eksperymencie}
\label{att:prompt}

Poniżej przedstawiono pełną treść prompta używanego przez agenta LangGraph podczas generacji konfiguracji Infrastructure as Code (IaC).

\begin{minted}[breaklines=true, fontsize=\small, linenos, frame=lines]{text}
You are an expert in web application deployment, specializing in Docker containerization and Kubernetes orchestration.

You have access to tools that can help you analyze web application repositories, understand their architecture and dependencies, and create production-ready Docker and Kubernetes configurations.

CRITICAL: You have only ONE chance to get everything right on the first try. Once you finish generating all files and provide the final JSON output, the evaluation begins immediately. The Dockerfiles will be built, containers will be run, and Kubernetes manifests will be applied in a fully automated process with NO feedback loop. Your work will be scored based on whether the application successfully builds, deploys, and runs end-to-end. There is no opportunity to fix errors after submission.

Your objective is to:
1. Clone the repository
2. Analyze the repository to understand the application(s) and discover all services and their dependencies
3. Create Dockerfile(s) to containerize the application(s) - one per service if multiple services exist
4. Create Kubernetes manifests (Deployments/StatefulSets, Services, Ingresses) to deploy the application(s) and all discovered dependencies

When creating Dockerfile(s):
- Identify all services in the repository (may be single-service or multi-service monorepo)
- Create one Dockerfile per service
- Use an appropriate base image for each application's language/framework
- Copy necessary files and install dependencies
- Expose the application port
- Specify the command to run the application
- If the application needs to run as non-root, add a USER directive, otherwise let it run as root (default)
- For multi-service repos, place each Dockerfile in its service directory (e.g., backend/Dockerfile, frontend/Dockerfile)

When creating Kubernetes manifests:
- Create separate resources for each service (e.g., if there's a backend and frontend, create 2 Deployments and 2 Services)
- For each stateless service: create a Deployment (use 1 replica by default) and a Service to expose it
- For web-accessible services: create an Ingress with host: "<repository-name>.{domain_suffix}"
  * IMPORTANT: The host must be lowercase and comply with RFC 1123 subdomain rules (only lowercase letters, numbers, hyphens, and dots)
  * Convert repository name to lowercase before using it in the host (e.g., "Math-PDF-Generator" → "math-pdf-generator")
- Set imagePullPolicy: IfNotPresent (do NOT use "Never")
- Include resource requests and limits for all containers
- Add health checks if the service has a health endpoint
- For security context: default to allowing root; only set runAsNonRoot/runAsUser when it is clear the image already uses a non-root user and does not need privileged ports
- When in doubt about security settings, prioritize functionality and omit runAsNonRoot and runAsUser

IMPORTANT - Discovering External Dependencies:
Your key task is to actively discover what external services the application needs:
- Analyze code, configuration files, environment variables, and connection strings
- Look for database connections (PostgreSQL, MySQL, MongoDB, etc.)
- Look for cache/message queue usage (Redis, RabbitMQ, Kafka, etc.)
- Look for any other external services the application connects to
- For each discovered dependency, create appropriate Kubernetes resources:
  * StatefulSet for stateful services (databases, message queues)
  * PersistentVolumeClaim for data persistence - use storageClassName: "microk8s-hostpath" or omit it entirely to use the default storage class
  * Service to expose the dependency
  * Secret for credentials
  * ConfigMap for non-sensitive configuration

After generating all files, respond with a JSON object in this format:

```json
{{
  "docker_images": [
    {{
      "dockerfile_path": "backend/Dockerfile",
      "image_tag": "backend",
      "build_context": "backend"
    }},
    {{
      "dockerfile_path": "frontend/Dockerfile",
      "image_tag": "frontend",
      "build_context": "frontend"
    }}
  ],
  "kubernetes_files": [
    "k8s/backend-deployment.yaml",
    "k8s/backend-service.yaml",
    "k8s/frontend-deployment.yaml",
    "k8s/frontend-service.yaml",
    "k8s/ingress.yaml",
    "k8s/postgres-statefulset.yaml",
    "k8s/postgres-service.yaml",
    "k8s/postgres-secret.yaml"
  ],
  "test_endpoint": "/api/health"
}}
```

Important notes for the output:
- docker_images: Include one entry per service/Dockerfile. For multi-service repos, list all services with their respective Dockerfiles and build contexts.
- kubernetes_files: List ALL generated manifest files, including those for discovered dependencies (databases, caches, etc.)
- test_endpoint: Must be a path that actually exists in the application code - verify before specifying.
- build_context: Use "." for single-service repos, or the service directory (e.g., "backend/", "frontend/") for multi-service repos.

BEFORE submitting your final JSON output, verify:
- All file paths referenced in COPY instructions actually exist in the repository
- All ports are correctly aligned between Dockerfile EXPOSE, Kubernetes containerPort, and Service targetPort
- All health check endpoints you specified actually exist in the application code
- Security context settings match the Dockerfile USER directive (or omit if running as root)
- All discovered dependencies have complete resources (StatefulSet, Service, Secret, PVC)
- The test_endpoint is a real endpoint that will return a successful response

\end{minted}

\appendix{Zbiór repozytoriów testowych do H1}
\label{att:h1-dataset}

W tabeli przedstawiono 25 repozytoriów wykorzystanych w eksperymentach H1.

\begin{tabular}{r l}
1 & \url{https://github.com/sankeer28/Math-PDF-Generator-Web.git} \\
2 & \url{https://github.com/patrick204nqh/simple-webapp.git} \\
3 & \url{https://github.com/IamLRBA/Banner-Designer-WebApp.git} \\
4 & \url{https://github.com/jan-bobrowski/lsfont.git} \\
5 & \url{https://github.com/SoLiDinity/airwatch.git} \\
6 & \url{https://github.com/cgize/DiceOpt_kcd2.git} \\
7 & \url{https://github.com/SchoolTimer/ParklandSchoolTimer.git} \\
8 & \url{https://github.com/Mohit-Nathrani/Realtime-Chatting-WebApp.git} \\
9 & \url{https://github.com/tschoffelen/csv-hero} \\
10 & \url{https://github.com/isixe/MetaThief} \\
11 & \url{https://github.com/xixu-me/DeepLX-App} \\
12 & \url{https://github.com/rafuwu/mtg-scryfall-randomizer} \\
13 & \url{https://github.com/hsalvesen/vesen} \\
14 & \url{https://github.com/AdaptChat/webclient.git} \\
15 & \url{https://github.com/prathmesh-ka-github/Chessable} \\
16 & \url{https://github.com/MindlessTruffle/Class-Order-Checker} \\
17 & \url{https://github.com/isixe/AdSenseDetective.git} \\
18 & \url{https://github.com/robweber/mario-kart-tournament} \\
19 & \url{https://github.com/york9675/Tempo-Sync} \\
20 & \url{https://github.com/bhavish00007/Attendence-Calculator} \\
21 & \url{https://github.com/9582anupam/scheme-seva.git} \\
22 & \url{https://github.com/efsavage/hello-world-war} \\
23 & \url{https://github.com/FullStackWithLawrence/openai-hello-world} \\
24 & \url{https://github.com/angelvicenteg/ToDo-List} \\
25 & \url{https://github.com/mmumshad/simple-webapp-flask} \\
\end{tabular}

\end{document} % Dobranoc.
