% Artykuł w recenzowanym czasopiśmie.
@article{szczypiorski2015,
    author    = {Szczypiorski, K. and Janicki, A. and Wendzel, S},
    title     = {{T}he {G}ood, {T}he {B}ad {A}nd {T}he {U}gly: {E}valuation of {W}i-{F}i {S}teganography},
    journal   = {Journal of Communications},
    volume    = {10},
    number    = {10},
    pages     = {747--752},
    publisher = {Journal of Communications (JCM)},
    year      = {2015}
}

% Książka.
@book{goossens93,
    author    = {Michel Goossens and Frank Mittelbach and Alexander Samarin},
    title     = {The LaTeX Companion},
    publisher = {Addison-Wesley},
    address   = {Reading, Massachusetts},
    year      = {1993}
}

% Fragment książki (np. zakres stron).
@inbook{wang97,
    author    = {Hao Wang},
    title     = {A Logical Journey: From G{\"o}del to Philosophy.},
    publisher = {A Bradford Book},
    pages     = {316},
    year      = {1997}
}

% Fragment książki (np. esej), posiadający własny tytuł.
@incollection{goedel95,
    author    = {Kurt G{\"o}del},
    title     = {Texts relating to the ontological proof},
    booktitle = {Unpublished Essays and Lectures},
    publisher = {Oxford University Press},
    pages     = {429--437},
    year      = {1995}
}

% Publikacja konferencyjna.
@inproceedings{benzmuller2014,
    author       = {{Ch}. Benzmuller and B. W. Paleo},
    title        = {Automating {G\"o}del’s {O}ntological {P}roof of {G}od’s {E}xistence with {H}igher-order {A}utomated {T}heorem {P}rovers},
    booktitle    = {European	Conference on Artificial Intelligence},
    publisher    = {IOS Press},
    howpublished = {Dostęp zdalny (10.04.2019): \url{http://page.mi.fu-berlin.de/cbenzmueller/papers/C40.pdf}},
    year         = {2014}
}

% Raport techniczny.
@techreport{duqu2011,
    author      = {Bencsáth, B. and Pék, G. and Buttyán, L. and Félegyházi M.},
    title       = {{D}uqu: {A} {S}tuxnet-like malware found in the wild},
    institution = {Laboratory of Cryptography and System Security, Hungary},
    year        = {2011}
}

% Specyfikacja techniczna.
@manual{shs2015,
    title        = {{FIPS} 180-4: {S}ecure {H}ash {S}tandard ({SHS})},
    howpublished = {Dostęp zdalny (13.03.2019): \url{https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf}},
    year         = {2015}
}

% Praca magisterska.
@mastersthesis{wozniak2018,
    author = {Woźniak, Piotr},
    title  = {{P}rogramowanie kwadratowe w usuwaniu efektu rozmycia ruchu w fotografii cyfrowej},
    school = {Wydział Elektroniki i Technik Informacyjnych, Politechnika Warszawska},
    year   = {2018}
}

% Nieopublikowany artykuł, dostępny np. tylko w internecie.
@unpublished{koons2005,
    author = {Koons, Robert C.},
    title  = {{S}obel on {G\"o}del’s {O}ntological {P}roof},
    note   = {Dostęp zdalny (25.04.2019): \url{http://www.robkoons.net/media/69b0dd04a9d2fc6dffff80b4ffffd524.pdf}},
    year   = {2005}
}

% Źródło innego typu, np. repozytorium na GitHubie.
@misc{dcp19,
    author       = {Brodzki, Artur M.},
    title        = {{I}mplementation of own steganography protocol {DCP}-19, loosely based on {HICCUPS}},
    howpublished = {Dostęp zdalny (14.03.2019): \url{https://github.com/ArturB/DCP-19}},
    year         = {2019}
}

% MOJE



@misc{malul_genkubesec_2024,
	title = {{GenKubeSec}: {LLM}-{Based} {Kubernetes} {Misconfiguration} {Detection}, {Localization}, {Reasoning}, and {Remediation}},
	shorttitle = {{GenKubeSec}},
	url = {http://arxiv.org/abs/2405.19954},
	doi = {10.48550/arXiv.2405.19954},
	abstract = {A key challenge associated with Kubernetes configuration files (KCFs) is that they are often highly complex and error-prone, leading to security vulnerabilities and operational setbacks. Rule-based (RB) tools for KCF misconfiguration detection rely on static rule sets, making them inherently limited and unable to detect newlydiscovered misconfigurations. RB tools also suffer from misdetection, since mistakes are likely when coding the detection rules. Recent methods for detecting and remediating KCF misconfigurations are limited in terms of their scalability and detection coverage, or due to the fact that they have high expertise requirements and do not offer automated remediation along with misconfiguration detection. Novel approaches that employ LLMs in their pipeline rely on API-based, general-purpose, and mainly commercial models. Thus, they pose security challenges, have inconsistent classification performance, and can be costly. In this paper, we propose GenKubeSec, a comprehensive and adaptive, LLM-based method, which, in addition to detecting a wide variety of KCF misconfigurations, also identifies the exact location of the misconfigurations and provides detailed reasoning about them, along with suggested remediation. When empirically compared with three industry-standard RB tools, GenKubeSec achieved equivalent precision (0.990 ± 0.020) and superior recall (0.999 ± 0.026). When a random sample of KCFs was examined by a Kubernetes security expert, GenKubeSec’s explanations as to misconfiguration localization, reasoning and remediation were 100\% correct, informative and useful. To facilitate further advancements in this domain, we share the unique dataset we collected, a unified misconfiguration index we developed for label standardization, our experimentation code, and GenKubeSec itself as an open-source tool. A video demonstrating our implementation of GenKubeSec can be found here: https://youtu.be/hBehYfdR-zM.},
	language = {en},
	urldate = {2025-01-23},
	publisher = {arXiv},
	author = {Malul, Ehud and Meidan, Yair and Mimran, Dudu and Elovici, Yuval and Shabtai, Asaf},
	month = may,
	year = {2024},
	note = {arXiv:2405.19954 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Cryptography and Security, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning},
	file = {PDF:/Users/rasztabigab/Zotero/storage/WDKEZU97/Malul et al. - 2024 - GenKubeSec LLM-Based Kubernetes Misconfiguration Detection, Localization, Reasoning, and Remediatio.pdf:application/pdf},
}

@misc{ueno_migrating_2024,
	title = {Migrating {Existing} {Container} {Workload} to {Kubernetes} -- {LLM} {Based} {Approach} and {Evaluation}},
	url = {http://arxiv.org/abs/2408.11428},
	doi = {10.48550/arXiv.2408.11428},
	abstract = {Although Kubernetes has become a widespread open-source system that automates the management of containerized applications, its complexity can be a significant barrier, particularly for application developers unfamiliar with it. One approach employs large language models (LLMs) to assist developers in generating Kubernetes manifests; however it is currently impossible to determine whether the output satisfies given specifications and is comprehensible. In this study, we proposed a benchmarking method for evaluating the effectiveness of LLMs in synthesizing manifests, using the Compose specification — a standard widely adopted by application developers — as input. The proposed benchmarking method revealed that LLMs generally produce accurate results that compensate for simple specification gaps. However, we also observed that inline comments for readability were often omitted, and completion accuracy was low for atypical inputs with unclear intentions.},
	language = {en},
	urldate = {2025-01-23},
	publisher = {arXiv},
	author = {Ueno, Masaru and Uchiumi, Tetsuya},
	month = aug,
	year = {2024},
	note = {arXiv:2408.11428 [cs]},
	keywords = {Computer Science - Software Engineering},
	file = {PDF:/Users/rasztabigab/Zotero/storage/LXZXIS4K/Ueno and Uchiumi - 2024 - Migrating Existing Container Workload to Kubernetes -- LLM Based Approach and Evaluation.pdf:application/pdf},
}

@inproceedings{kratzke_dont_2024,
	address = {Angers, France},
	title = {Don't {Train}, {Just} {Prompt}: {Towards} a {Prompt} {Engineering} {Approach} for a {More} {Generative} {Container} {Orchestration} {Management}:},
	isbn = {978-989-758-701-6},
	shorttitle = {Don't {Train}, {Just} {Prompt}},
	url = {https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0012710300003711},
	doi = {10.5220/0012710300003711},
	abstract = {Background: The intricate architecture of container orchestration systems like Kubernetes relies on the critical role of declarative manifest ﬁles that serve as the blueprints for orchestration. However, managing these manifest ﬁles often presents complex challenges requiring signiﬁcant DevOps expertise. Methodology: This position paper explores using Large Language Models (LLMs) to automate the generation of Kubernetes manifest ﬁles through natural language speciﬁcations and prompt engineering, aiming to simplify Kubernetes management. The study evaluates these LLMs using Zero-Shot, Few-Shot, and Prompt-Chaining techniques against DevOps requirements and the ability to support fully automated deployment pipelines. Results show that LLMs can produce Kubernetes manifests with varying degrees of manual intervention, with GPT-4 and GPT-3.5 showing potential for fully automated deployments. Interestingly, smaller models sometimes outperform larger ones, questioning the assumption that bigger is always better. Conclusion: The study emphasizes that prompt engineering is critical to optimizing LLM outputs for Kubernetes. It suggests further research into prompt strategies and LLM comparisons and highlights a promising research direction for integrating LLMs into automatic deployment pipelines.},
	language = {en},
	urldate = {2025-01-23},
	booktitle = {Proceedings of the 14th {International} {Conference} on {Cloud} {Computing} and {Services} {Science}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Kratzke, Nane and Drews, André},
	year = {2024},
	pages = {248--256},
	file = {PDF:/Users/rasztabigab/Zotero/storage/AXC6FJA9/Kratzke and Drews - 2024 - Don't Train, Just Prompt Towards a Prompt Engineering Approach for a More Generative Container Orch.pdf:application/pdf},
}

@inproceedings{lanciano_analyzing_2023,
	address = {Prague, Czech Republic},
	title = {Analyzing {Declarative} {Deployment} {Code} with {Large} {Language} {Models}:},
	isbn = {978-989-758-650-7},
	shorttitle = {Analyzing {Declarative} {Deployment} {Code} with {Large} {Language} {Models}},
	url = {https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0011991200003488},
	doi = {10.5220/0011991200003488},
	abstract = {In the cloud-native era, developers have at their disposal an unprecedented landscape of services to build scalable distributed systems. The DevOps paradigm emerged as a response to the increasing necessity of better automations, capable of dealing with the complexity of modern cloud systems. For instance, Infrastructure-asCode tools provide a declarative way to deﬁne, track, and automate changes to the infrastructure underlying a cloud application. Assuring the quality of this part of a code base is of utmost importance. However, learning to produce robust deployment speciﬁcations is not an easy feat, and for the domain experts it is timeconsuming to conduct code-reviews and transfer the appropriate knowledge to novice members of the team. Given the abundance of data generated throughout the DevOps cycle, machine learning (ML) techniques seem a promising way to tackle this problem. In this work, we propose an approach based on Large Language Models to analyze declarative deployment code and automatically provide QA-related recommendations to developers, such that they can beneﬁt of established best practices and design patterns. We developed a prototype of our proposed ML pipeline, and empirically evaluated our approach on a collection of Kubernetes manifests exported from a repository of internal projects at Nokia Bell Labs.},
	language = {en},
	urldate = {2025-01-23},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Cloud} {Computing} and {Services} {Science}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Lanciano, Giacomo and Stein, Manuel and Hilt, Volker and Cucinotta, Tommaso},
	year = {2023},
	pages = {289--296},
	file = {PDF:/Users/rasztabigab/Zotero/storage/DNJ6HQGE/Lanciano et al. - 2023 - Analyzing Declarative Deployment Code with Large Language Models.pdf:application/pdf},
}

@inproceedings{pujar_invited_2023,
	address = {San Francisco, CA, USA},
	title = {Invited: {Automated} {Code} generation for {Information} {Technology} {Tasks} in {YAML} through {Large} {Language} {Models}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {9798350323481},
	shorttitle = {Invited},
	url = {https://ieeexplore.ieee.org/document/10247987/},
	doi = {10.1109/DAC56929.2023.10247987},
	abstract = {The recent improvement in code generation capabilities due to the use of large language models has mainly beneﬁted general purpose programming languages. Domain speciﬁc languages, such as the ones used for IT Automation, received far less attention, despite involving many active developers and being an essential component of modern cloud platforms. This work focuses on the generation of Ansible YAML, a widely used markup language for IT Automation. We present Ansible Wisdom, a natural-language to Ansible YAML code generation tool, aimed at improving IT automation productivity. Results show that Ansible Wisdom can accurately generate Ansible script from natural language prompts with performance comparable or better than existing state of the art code generation models.},
	language = {en},
	urldate = {2025-01-23},
	booktitle = {2023 60th {ACM}/{IEEE} {Design} {Automation} {Conference} ({DAC})},
	publisher = {IEEE},
	author = {Pujar, Saurabh and Buratti, Luca and Guo, Xiaojie and Dupuis, Nicolas and Lewis, Burn and Suneja, Sahil and Sood, Atin and Nalawade, Ganesh and Jones, Matt and Morari, Alessandro and Puri, Ruchir},
	month = jul,
	year = {2023},
	pages = {1--4},
	file = {PDF:/Users/rasztabigab/Zotero/storage/F77VRJ2R/Pujar et al. - 2023 - Invited Automated Code generation for Information Technology Tasks in YAML through Large Language M.pdf:application/pdf},
}

@misc{hu_llm-based_2025,
	title = {An {LLM}-based {Agent} for {Reliable} {Docker} {Environment} {Configuration}},
	url = {http://arxiv.org/abs/2502.13681},
	doi = {10.48550/arXiv.2502.13681},
	abstract = {Environment configuration is a critical yet time-consuming step in software development, especially when dealing with unfamiliar code repositories. While Large Language Models (LLMs) demonstrate the potential to accomplish software engineering tasks, existing methods for environment configuration often rely on manual efforts or fragile scripts, leading to inefficiencies and unreliable outcomes. We introduce Repo2Run, the first LLM-based agent designed to fully automate environment configuration and generate executable Dockerfiles for arbitrary Python repositories. We address two major challenges: (1) enabling the LLM agent to configure environments within isolated Docker containers, and (2) ensuring the successful configuration process is recorded and accurately transferred to a Dockerfile without error. To achieve this, we propose atomic configuration synthesis, featuring a dual-environment architecture (internal and external environment) with a rollback mechanism to prevent environment “pollution” from failed commands, guaranteeing atomic execution (execute fully or not at all) and a Dockerfile generator to transfer successful configuration steps into runnable Dockerfiles. We evaluate Repo2Run on our proposed benchmark of 420 recent Python repositories with unit tests, where it achieves an 86.0\% success rate, outperforming the best baseline by 63.9\%. Repo2Run is available at https://github.com/bytedance/Repo2Run.},
	language = {en},
	urldate = {2025-03-31},
	publisher = {arXiv},
	author = {Hu, Ruida and Peng, Chao and Wang, Xinchen and Gao, Cuiyun},
	month = mar,
	year = {2025},
	note = {arXiv:2502.13681 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Software Engineering, Computer Science - Artificial Intelligence},
	file = {PDF:/Users/rasztabigab/Zotero/storage/LB7XG52V/Hu et al. - 2025 - An LLM-based Agent for Reliable Docker Environment Configuration.pdf:application/pdf},
}

@misc{srivatsa_survey_2024,
	title = {A {Survey} of using {Large} {Language} {Models} for {Generating} {Infrastructure} as {Code}},
	url = {http://arxiv.org/abs/2404.00227},
	doi = {10.48550/arXiv.2404.00227},
	abstract = {Infrastructure as Code (IaC) is a revolutionary approach which has gained significant prominence in the Industry. IaC manages and provisions IT infrastructure using machinereadable code by enabling automation, consistency across the environments, reproducibility, version control, error reduction and enhancement in scalability. However, IaC orchestration is often a painstaking effort which requires specialised skills as well as a lot of manual effort. Automation of IaC is a necessity in the present conditions of the Industry and in this survey, we study the feasibility of applying Large Language Models (LLM) to address this problem. LLMs are large neural network-based models which have demonstrated significant language processing abilities and shown to be capable of following a range of instructions within a broad scope. Recently, they have also been adapted for code understanding and generation tasks successfully, which makes them a promising choice for the automatic generation of IaC configurations. In this survey, we delve into the details of IaC, usage of IaC in different platforms, their challenges, LLMs in terms of code-generation aspects and the importance of LLMs in IaC along with our own experiments. Finally, we conclude by presenting the challenges in this area and highlighting the scope for future research.},
	language = {en},
	urldate = {2025-03-31},
	publisher = {arXiv},
	author = {Srivatsa, Kalahasti Ganesh and Mukhopadhyay, Sabyasachi and Katrapati, Ganesh and Shrivastava, Manish},
	month = mar,
	year = {2024},
	note = {arXiv:2404.00227 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Software Engineering},
	file = {PDF:/Users/rasztabigab/Zotero/storage/MDY23SUQ/Srivatsa et al. - 2024 - A Survey of using Large Language Models for Generating Infrastructure as Code.pdf:application/pdf},
}

@article{kon_iac-eval_nodate,
	title = {{IaC}-{Eval}: {A} {Code} {Generation} {Benchmark} for {Cloud} {Infrastructure}-as-{Code} {Programs}},
	abstract = {Infrastructure-as-Code (IaC), an important component of cloud computing, allows the definition of cloud infrastructure in high-level programs. However, developing IaC programs is challenging, complicated by factors that include the burgeoning complexity of the cloud ecosystem (e.g., diversity of cloud services and workloads), and the relative scarcity of IaC-specific code examples and public repositories. While large language models (LLMs) have shown promise in general code generation and could potentially aid in IaC development, no benchmarks currently exist for evaluating their ability to generate IaC code. We present IaC-Eval, a first step in this research direction. IaC-Eval’s dataset includes 458 human-curated scenarios covering a wide range of popular AWS services, at varying difficulty levels. Each scenario mainly comprises a natural language IaC problem description and an infrastructure intent specification. The former is fed as user input to the LLM, while the latter is a general notion used to verify if the generated IaC program conforms to the user’s intent; by making explicit the problem’s requirements that can encompass various cloud services, resources and internal infrastructure details. Our in-depth evaluation shows that contemporary LLMs perform poorly on IaC-Eval, with the top-performing model, GPT-4, obtaining a pass@1 accuracy of 19.36\%. In contrast, it scores 86.6\% on EvalPlus, a popular Python code generation benchmark, highlighting a need for advancements in this domain. We open-source the IaC-Eval dataset and evaluation framework at https://github.com/autoiac-project/iac-eval to enable future research on LLM-based IaC code generation.},
	language = {en},
	author = {Kon, Patrick Tser Jern and Liu, Jiachen and Qiu, Yiming and Fan, Weijun and He, Ting and Lin, Lei and Zhang, Haoran and Park, Owen M and Elengikal, George S and Kang, Yuxin and Chen, Ang and Chowdhury, Mosharaf and Lee, Myungjin and Wang, Xinyu},
	file = {PDF:/Users/rasztabigab/Zotero/storage/2LCEBURH/Kon et al. - IaC-Eval A Code Generation Benchmark for Cloud Infrastructure-as-Code Programs.pdf:application/pdf},
}

@inproceedings{low_repairing_2024,
	address = {Pittsburgh, PA, USA},
	title = {Repairing {Infrastructure}-as-{Code} using {Large} {Language} {Models}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {9798350391930},
	url = {https://ieeexplore.ieee.org/document/10734039/},
	doi = {10.1109/SecDev61143.2024.00008},
	abstract = {Infrastructure-as-Code (IaC) is the practice of provisioning and managing cloud resources using machine-readable code. IaC is seeing increased adoption because it enhances transparency and reliability of infrastructure operations. However, as any software code, IaC can also contain misconﬁgurations, which can lead to insecure infrastructure, which may result in data breaches. Existing IaC scanning tools are able to detect common misconﬁgurations in IaC but they require IaC developers to manually repair the code. Recent advances in Large Language Models (LLMs) have led to promising results in applying LLMs to Automatic Program Repair (APR) tasks for code written in different languages. In this work, we propose an LLM-based approach to ﬁx misconﬁgurations in IaC code. After misconﬁgurations in IaC code are identiﬁed by scanning tools, we feed the LLMs with the IaC code, details about the misconﬁgurations, and additional context provided by a human-in-the-loop and prompt the LLM to generate the repaired IaC code. We tested our approach on several vulnerable IaC repositories and found that the GPT-4 model from OpenAI suggests ﬁxes that reduce up to 84.7\% of the misconﬁguration alarms produced by the scanners and our two-pass solution signiﬁcantly improves the performance over a one-pass only approach. However, of the ﬁxes suggested, we manually determined that only 79.6\% actually solve the problem, while the remaining 20.4\% are hallucinated ﬁxes. Speciﬁcally, LLM hallucinations in the generated outputs pass checks for misconﬁgurations but fail other syntax and schema validation checks or do not address the underlying security issue. We propose a few potential approaches to tackle this challenge.},
	language = {en},
	urldate = {2025-03-31},
	booktitle = {2024 {IEEE} {Secure} {Development} {Conference} ({SecDev})},
	publisher = {IEEE},
	author = {Low, En and Cheh, Carmen and Chen, Binbin},
	month = oct,
	year = {2024},
	pages = {20--27},
	file = {PDF:/Users/rasztabigab/Zotero/storage/65ZKZ3MJ/Low et al. - 2024 - Repairing Infrastructure-as-Code using Large Language Models.pdf:application/pdf},
}

@misc{fu_security_2025,
	title = {Security {Weaknesses} of {Copilot}-{Generated} {Code} in {GitHub} {Projects}: {An} {Empirical} {Study}},
	shorttitle = {Security {Weaknesses} of {Copilot}-{Generated} {Code} in {GitHub} {Projects}},
	url = {http://arxiv.org/abs/2310.02059},
	doi = {10.48550/arXiv.2310.02059},
	abstract = {YUJIA FU, School of Computer Science, Wuhan University, China PENG LIANG∗, School of Computer Science, Wuhan University, China AMJED TAHIR, Massey University, New Zealand ZENGYANG LI, School of Computer Science, Central China Normal University, China MOJTABA SHAHIN, RMIT University, Australia JIAXIN YU, School of Computer Science, Wuhan University, China JINFU CHEN, School of Computer Science, Wuhan University, China Modern code generation tools utilizing AI models like Large Language Models (LLMs) have gained increased popularity due to their ability to produce functional code. However, their usage presents security challenges, often resulting in insecure code merging into the code base. Thus, evaluating the quality of generated code, especially its security, is crucial. While prior research explored various aspects of code generation, the focus on security has been limited, mostly examining code produced in controlled environments rather than open source development scenarios. To address this gap, we conducted an empirical study, analyzing code snippets generated by GitHub Copilot and two other AI code generation tools (i.e., CodeWhisperer and Codeium) from GitHub projects. Our analysis identified 733 snippets, revealing a high likelihood of security weaknesses, with 29.5\% of Python and 24.2\% of JavaScript snippets affected. These issues span 43 Common Weakness Enumeration (CWE) categories, including significant ones like CWE-330: Use of Insufficiently Random Values, CWE-94: Improper Control of Generation of Code, and CWE-79: Cross-site Scripting. Notably, eight of those CWEs are among the 2023 CWE Top-25, highlighting their severity. We further examined using Copilot Chat to fix security issues in Copilot-generated code by providing Copilot Chat with warning messages from the static analysis tools, and up to 55.5\% of the security issues can be fixed. We finally provide the suggestions for mitigating security issues in generated code. CCS Concepts: • Software and its engineering → Software development techniques; • Security and privacy → Software security engineering.},
	language = {en},
	urldate = {2025-03-31},
	publisher = {arXiv},
	author = {Fu, Yujia and Liang, Peng and Tahir, Amjed and Li, Zengyang and Shahin, Mojtaba and Yu, Jiaxin and Chen, Jinfu},
	month = feb,
	year = {2025},
	note = {arXiv:2310.02059 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Software Engineering},
	file = {PDF:/Users/rasztabigab/Zotero/storage/6SMHPY4D/Fu et al. - 2025 - Security Weaknesses of Copilot-Generated Code in GitHub Projects An Empirical Study.pdf:application/pdf},
}

@misc{liu_prompt_2024,
	title = {Prompt {Injection} attack against {LLM}-integrated {Applications}},
	url = {http://arxiv.org/abs/2306.05499},
	doi = {10.48550/arXiv.2306.05499},
	abstract = {Large Language Models (LLMs), renowned for their superior proficiency in language comprehension and generation, stimulate a vibrant ecosystem of applications around them. However, their extensive assimilation into various services introduces significant security risks. This study deconstructs the complexities and implications of prompt injection attacks on actual LLM-integrated applications. Initially, we conduct an exploratory analysis on ten commercial applications, highlighting the constraints of current attack strategies in practice. Prompted by these limitations, we subsequently formulate HOUYI, a novel black-box prompt injection attack technique, which draws inspiration from traditional web injection attacks. HOUYI is compartmentalized into three crucial elements: a seamlessly-incorporated pre-constructed prompt, an injection prompt inducing context partition, and a malicious payload designed to fulfill the attack objectives. Leveraging HOUYI, we unveil previously unknown and severe attack outcomes, such as unrestricted arbitrary LLM usage and uncomplicated application prompt theft. We deploy HOUYI on 36 actual LLM-integrated applications and discern 31 applications susceptible to prompt injection. 10 vendors have validated our discoveries, including Notion, which has the potential to impact millions of users. Our investigation illuminates both the possible risks of prompt injection attacks and the possible tactics for mitigation.},
	language = {en},
	urldate = {2025-03-31},
	publisher = {arXiv},
	author = {Liu, Yi and Deng, Gelei and Li, Yuekang and Wang, Kailong and Wang, Zihao and Wang, Xiaofeng and Zhang, Tianwei and Liu, Yepang and Wang, Haoyu and Zheng, Yan and Liu, Yang},
	month = mar,
	year = {2024},
	note = {arXiv:2306.05499 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Cryptography and Security, Computer Science - Software Engineering, Computer Science - Artificial Intelligence},
	file = {PDF:/Users/rasztabigab/Zotero/storage/494GYLID/Liu et al. - 2024 - Prompt Injection attack against LLM-integrated Applications.pdf:application/pdf},
}

@misc{anthropic_claude,
  title={Claude - Anthropic's Constitutional AI Language Model},
  author={Anthropic},
  year={2023},
  howpublished={\\url{https://www.anthropic.com/index/claude}},
  note={Accessed: 2024-04-22}
}


@misc{zhao_survey_2025,
	title = {A {Survey} of {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2303.18223},
	doi = {10.48550/arXiv.2303.18223},
	abstract = {Ever since the Turing Test was proposed in the 1950s, humans have explored the mastering of language intelligence by machine. Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable artificial intelligence (AI) algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pretraining Transformer models over large-scale corpora, showing strong capabilities in solving various natural language processing (NLP) tasks. Since the researchers have found that model scaling can lead to an improved model capacity, they further investigate the scaling effect by increasing the parameter scale to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement, but also exhibit some special abilities (e.g., incontext learning) that are not present in small-scale language models (e.g., BERT). To discriminate the language models in different parameter scales, the research community has coined the term large language models (LLM) for the PLMs of significant size (e.g., containing tens or hundreds of billions of parameters). Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT (a powerful AI chatbot developed based on LLMs), which has attracted widespread attention from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. Considering this rapid technical progress, in this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation. Furthermore, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions. This survey provides an up-to-date review of the literature on LLMs, which can be a useful resource for both researchers and engineers.},
	language = {en},
	urldate = {2025-04-22},
	publisher = {arXiv},
	author = {Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and Du, Yifan and Yang, Chen and Chen, Yushuo and Chen, Zhipeng and Jiang, Jinhao and Ren, Ruiyang and Li, Yifan and Tang, Xinyu and Liu, Zikang and Liu, Peiyu and Nie, Jian-Yun and Wen, Ji-Rong},
	month = mar,
	year = {2025},
	note = {arXiv:2303.18223 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {PDF:/Users/rasztabigab/Zotero/storage/3M8LRM2V/Zhao et al. - 2025 - A Survey of Large Language Models.pdf:application/pdf},
}

@misc{almazrouei_falcon_2023,
	title = {The {Falcon} {Series} of {Open} {Language} {Models}},
	url = {http://arxiv.org/abs/2311.16867},
	doi = {10.48550/arXiv.2311.16867},
	abstract = {We introduce the Falcon series: 7B, 40B, and 180B parameters causal decoderonly models trained on a diverse high-quality corpora predominantly assembled from web data. The largest model, Falcon-180B, has been trained on over 3.5 trillion tokens of text–the largest openly documented pretraining run. Falcon-180B significantly outperforms models such as PaLM or Chinchilla, and improves upon concurrently developed models such as LLaMA 2 or Inflection-1. It nears the performance of PaLM-2-Large at a reduced pretraining and inference cost, making it, to our knowledge, one of the three best language models in the world along with GPT-4 and PaLM-2-Large. We report detailed evaluations, as well as a deep dive into the methods and custom tooling employed to pretrain Falcon. Notably, we report on our custom distributed training codebase, allowing us to efficiently pretrain these models on up to 4,096 A100s on cloud AWS infrastructure with limited interconnect. We release a 600B tokens extract of our web dataset, as well as the Falcon-7/40/180B models under a permissive license to foster open-science and accelerate the development of an open ecosystem of large language models.},
	language = {en},
	urldate = {2025-04-22},
	publisher = {arXiv},
	author = {Almazrouei, Ebtesam and Alobeidli, Hamza and Alshamsi, Abdulaziz and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah, Mérouane and Goffinet, Étienne and Hesslow, Daniel and Launay, Julien and Malartic, Quentin and Mazzotta, Daniele and Noune, Badreddine and Pannier, Baptiste and Penedo, Guilherme},
	month = nov,
	year = {2023},
	note = {arXiv:2311.16867 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {PDF:/Users/rasztabigab/Zotero/storage/2BFPXKAF/Almazrouei et al. - 2023 - The Falcon Series of Open Language Models.pdf:application/pdf},
}

@misc{touvron_llama_2023,
	title = {{LLaMA}: {Open} and {Efficient} {Foundation} {Language} {Models}},
	shorttitle = {{LLaMA}},
	url = {http://arxiv.org/abs/2302.13971},
	doi = {10.48550/arXiv.2302.13971},
	abstract = {We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community1.},
	language = {en},
	urldate = {2025-04-22},
	publisher = {arXiv},
	author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothée and Rozière, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
	month = feb,
	year = {2023},
	note = {arXiv:2302.13971 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {PDF:/Users/rasztabigab/Zotero/storage/V8BKV8XC/Touvron et al. - 2023 - LLaMA Open and Efficient Foundation Language Models.pdf:application/pdf},
}

@misc{brown_language_2020,
	title = {Language {Models} are {Few}-{Shot} {Learners}},
	url = {http://arxiv.org/abs/2005.14165},
	doi = {10.48550/arXiv.2005.14165},
	abstract = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by ﬁne-tuning on a speciﬁc task. While typically task-agnostic in architecture, this method still requires task-speciﬁc ﬁne-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions – something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art ﬁnetuning approaches. Speciﬁcally, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or ﬁne-tuning, with tasks and few-shot demonstrations speciﬁed purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-ﬂy reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3’s few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we ﬁnd that GPT-3 can generate samples of news articles which human evaluators have difﬁculty distinguishing from articles written by humans. We discuss broader societal impacts of this ﬁnding and of GPT-3 in general.},
	language = {en},
	urldate = {2025-04-22},
	publisher = {arXiv},
	author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	month = jul,
	year = {2020},
	note = {arXiv:2005.14165 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {PDF:/Users/rasztabigab/Zotero/storage/L326VAMD/Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf:application/pdf},
}


@article{burns_borg_2016,
	title = {Borg, {Omega}, and {Kubernetes}},
	volume = {59},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/2890784},
	doi = {10.1145/2890784},
	abstract = {Lessons learned from three container-management systems over a decade.},
	language = {en},
	number = {5},
	urldate = {2025-04-22},
	journal = {Communications of the ACM},
	author = {Burns, Brendan and Grant, Brian and Oppenheimer, David and Brewer, Eric and Wilkes, John},
	month = apr,
	year = {2016},
	pages = {50--57},
	file = {PDF:/Users/rasztabigab/Zotero/storage/8Z68REW6/Burns et al. - 2016 - Borg, Omega, and Kubernetes.pdf:application/pdf},
}

@article{merkel_docker_nodate,
	title = {Docker: {Lightweight} {Linux} {Containers} for {Consistent} {Development} and {Deployment}},
	abstract = {Take on “dependency hell” with Docker containers, the lightweight and nimble cousin of VMs. Learn how Docker makes applications portable and isolated by packaging them in containers based on LXC technology.},
	language = {en},
	author = {Merkel, Dirk},
	file = {PDF:/Users/rasztabigab/Zotero/storage/EVINSGHH/Merkel - Docker Lightweight Linux Containers for Consistent Development and Deployment.pdf:application/pdf},
}


@article{liu_pre-train_2023,
	title = {Pre-train, {Prompt}, and {Predict}: {A} {Systematic} {Survey} of {Prompting} {Methods} in {Natural} {Language} {Processing}},
	volume = {55},
	issn = {0360-0300, 1557-7341},
	shorttitle = {Pre-train, {Prompt}, and {Predict}},
	url = {https://dl.acm.org/doi/10.1145/3560815},
	doi = {10.1145/3560815},
	language = {en},
	number = {9},
	urldate = {2025-04-22},
	journal = {ACM Computing Surveys},
	author = {Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
	month = sep,
	year = {2023},
	pages = {1--35},
	file = {PDF:/Users/rasztabigab/Zotero/storage/C6BGEL8N/Liu et al. - 2023 - Pre-train, Prompt, and Predict A Systematic Survey of Prompting Methods in Natural Language Process.pdf:application/pdf},
}

@article{pahl_infrastructure_nodate,
	title = {Infrastructure as {Code} – {Technology} {Review} and {Research} {Challenges}},
	abstract = {The quality of software management in infrastructure operations for application software is important as automation in software operations continues to grow. Infrastructure as Code (IaC) refers to a systematic, technology-supported approach to manage deployment infrastructure for software applications. Sample contexts are general software automation, but also cloud and edge and various software-defined networking applications. DevOps (development and operations) practices, which are already applied in the Infrastructure as Code (IaC) context, need to be extended to cover the whole IaC life cycle from code generation to dynamic, automated control. The ultimate objective would range from IaC generation to full self-adaptation of IaC code in an automated setting. We review available IaC technologies based on a comprehensive comparison framework to capture the state-of-the-art. We also introduce an IaC-specific DevOps process. This serves as a basis to identify open research challenges. A discussion of defect categories is at the centre of this process.},
	language = {en},
	author = {Pahl, Claus and Gunduz, Niyazi Gokberk and Sezen, Ovgum Can and Ghamgosar, Ali and Ioini, Nabil El},
	file = {PDF:/Users/rasztabigab/Zotero/storage/JCXHY7J2/Pahl et al. - Infrastructure as Code – Technology Review and Research Challenges.pdf:application/pdf},
}

@misc{docker_genai,
	title = {How to {Create} {Dockerfiles} with {GenAI}},
	url = {https://www.docker.com/blog/how-to-create-dockerfiles-with-genai/},
	language = {en},
	urldate = {2025-04-25},
	author = {{Docker Labs}},
}

@misc{checkov,
	title = {Dokumentacja skanera {Checkov}},
	url = {https://www.checkov.io/1.Welcome/What%20is%20Checkov.html},
	language = {en},
	urldate = {2025-04-26}
}

@misc{kubelinter,
	title = {Dokumentacja skanera {Kubelinter}},
	url = {https://docs.kubelinter.io/},
	language = {en},
	urldate = {2025-04-26}
}

@misc{terrascan,
	title = {Dokumentacja skanera {Terrascan}},
	url = {https://runterrascan.io/docs/},
	language = {en},
	urldate = {2025-04-26}
}

@misc{cwetop25,
	title = {Lista najbardziej krytycznych luk bezpieczeństwa w oprogramowaniu - {CWE} {Top} 25},
	url = {https://cwe.mitre.org/top25/},
	language = {en},
	urldate = {2025-04-26}
}


@misc{vaswani_attention_2023,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	doi = {10.48550/arXiv.1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	language = {en},
	urldate = {2025-06-07},
	publisher = {arXiv},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = aug,
	year = {2023},
	note = {arXiv:1706.03762 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: 15 pages, 5 figures},
}
