% Artykuł w recenzowanym czasopiśmie.
@article{szczypiorski2015,
    author    = {Szczypiorski, K. and Janicki, A. and Wendzel, S},
    title     = {{T}he {G}ood, {T}he {B}ad {A}nd {T}he {U}gly: {E}valuation of {W}i-{F}i {S}teganography},
    journal   = {Journal of Communications},
    volume    = {10},
    number    = {10},
    pages     = {747--752},
    publisher = {Journal of Communications (JCM)},
    year      = {2015}
}

% Książka.
@book{goossens93,
    author    = {Michel Goossens and Frank Mittelbach and Alexander Samarin},
    title     = {The LaTeX Companion},
    publisher = {Addison-Wesley},
    address   = {Reading, Massachusetts},
    year      = {1993}
}

% Fragment książki (np. zakres stron).
@inbook{wang97,
    author    = {Hao Wang},
    title     = {A Logical Journey: From G{\"o}del to Philosophy.},
    publisher = {A Bradford Book},
    pages     = {316},
    year      = {1997}
}

% Fragment książki (np. esej), posiadający własny tytuł.
@incollection{goedel95,
    author    = {Kurt G{\"o}del},
    title     = {Texts relating to the ontological proof},
    booktitle = {Unpublished Essays and Lectures},
    publisher = {Oxford University Press},
    pages     = {429--437},
    year      = {1995}
}

% Publikacja konferencyjna.
@inproceedings{benzmuller2014,
    author       = {{Ch}. Benzmuller and B. W. Paleo},
    title        = {Automating {G\"o}del’s {O}ntological {P}roof of {G}od’s {E}xistence with {H}igher-order {A}utomated {T}heorem {P}rovers},
    booktitle    = {European	Conference on Artificial Intelligence},
    publisher    = {IOS Press},
    howpublished = {Dostęp zdalny (10.04.2019): \url{http://page.mi.fu-berlin.de/cbenzmueller/papers/C40.pdf}},
    year         = {2014}
}

% Raport techniczny.
@techreport{duqu2011,
    author      = {Bencsáth, B. and Pék, G. and Buttyán, L. and Félegyházi M.},
    title       = {{D}uqu: {A} {S}tuxnet-like malware found in the wild},
    institution = {Laboratory of Cryptography and System Security, Hungary},
    year        = {2011}
}

% Specyfikacja techniczna.
@manual{shs2015,
    title        = {{FIPS} 180-4: {S}ecure {H}ash {S}tandard ({SHS})},
    howpublished = {Dostęp zdalny (13.03.2019): \url{https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf}},
    year         = {2015}
}

% Praca magisterska.
@mastersthesis{wozniak2018,
    author = {Woźniak, Piotr},
    title  = {{P}rogramowanie kwadratowe w usuwaniu efektu rozmycia ruchu w fotografii cyfrowej},
    school = {Wydział Elektroniki i Technik Informacyjnych, Politechnika Warszawska},
    year   = {2018}
}

% Nieopublikowany artykuł, dostępny np. tylko w internecie.
@unpublished{koons2005,
    author = {Koons, Robert C.},
    title  = {{S}obel on {G\"o}del’s {O}ntological {P}roof},
    note   = {Dostęp zdalny (25.04.2019): \url{http://www.robkoons.net/media/69b0dd04a9d2fc6dffff80b4ffffd524.pdf}},
    year   = {2005}
}

% Źródło innego typu, np. repozytorium na GitHubie.
@misc{dcp19,
    author       = {Brodzki, Artur M.},
    title        = {{I}mplementation of own steganography protocol {DCP}-19, loosely based on {HICCUPS}},
    howpublished = {Dostęp zdalny (14.03.2019): \url{https://github.com/ArturB/DCP-19}},
    year         = {2019}
}

% MOJE



@misc{malul_genkubesec_2024,
	title = {{GenKubeSec}: {LLM}-{Based} {Kubernetes} {Misconfiguration} {Detection}, {Localization}, {Reasoning}, and {Remediation}},
	shorttitle = {{GenKubeSec}},
	url = {http://arxiv.org/abs/2405.19954},
	doi = {10.48550/arXiv.2405.19954},
	abstract = {A key challenge associated with Kubernetes configuration files (KCFs) is that they are often highly complex and error-prone, leading to security vulnerabilities and operational setbacks. Rule-based (RB) tools for KCF misconfiguration detection rely on static rule sets, making them inherently limited and unable to detect newlydiscovered misconfigurations. RB tools also suffer from misdetection, since mistakes are likely when coding the detection rules. Recent methods for detecting and remediating KCF misconfigurations are limited in terms of their scalability and detection coverage, or due to the fact that they have high expertise requirements and do not offer automated remediation along with misconfiguration detection. Novel approaches that employ LLMs in their pipeline rely on API-based, general-purpose, and mainly commercial models. Thus, they pose security challenges, have inconsistent classification performance, and can be costly. In this paper, we propose GenKubeSec, a comprehensive and adaptive, LLM-based method, which, in addition to detecting a wide variety of KCF misconfigurations, also identifies the exact location of the misconfigurations and provides detailed reasoning about them, along with suggested remediation. When empirically compared with three industry-standard RB tools, GenKubeSec achieved equivalent precision (0.990 ± 0.020) and superior recall (0.999 ± 0.026). When a random sample of KCFs was examined by a Kubernetes security expert, GenKubeSec’s explanations as to misconfiguration localization, reasoning and remediation were 100\% correct, informative and useful. To facilitate further advancements in this domain, we share the unique dataset we collected, a unified misconfiguration index we developed for label standardization, our experimentation code, and GenKubeSec itself as an open-source tool. A video demonstrating our implementation of GenKubeSec can be found here: https://youtu.be/hBehYfdR-zM.},
	language = {en},
	urldate = {2025-01-23},
	publisher = {arXiv},
	author = {Malul, Ehud and Meidan, Yair and Mimran, Dudu and Elovici, Yuval and Shabtai, Asaf},
	month = may,
	year = {2024},
	note = {arXiv:2405.19954 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Cryptography and Security, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning},
	file = {PDF:/Users/rasztabigab/Zotero/storage/WDKEZU97/Malul et al. - 2024 - GenKubeSec LLM-Based Kubernetes Misconfiguration Detection, Localization, Reasoning, and Remediatio.pdf:application/pdf},
}

@misc{ueno_migrating_2024,
	title = {Migrating {Existing} {Container} {Workload} to {Kubernetes} -- {LLM} {Based} {Approach} and {Evaluation}},
	url = {http://arxiv.org/abs/2408.11428},
	doi = {10.48550/arXiv.2408.11428},
	abstract = {Although Kubernetes has become a widespread open-source system that automates the management of containerized applications, its complexity can be a significant barrier, particularly for application developers unfamiliar with it. One approach employs large language models (LLMs) to assist developers in generating Kubernetes manifests; however it is currently impossible to determine whether the output satisfies given specifications and is comprehensible. In this study, we proposed a benchmarking method for evaluating the effectiveness of LLMs in synthesizing manifests, using the Compose specification — a standard widely adopted by application developers — as input. The proposed benchmarking method revealed that LLMs generally produce accurate results that compensate for simple specification gaps. However, we also observed that inline comments for readability were often omitted, and completion accuracy was low for atypical inputs with unclear intentions.},
	language = {en},
	urldate = {2025-01-23},
	publisher = {arXiv},
	author = {Ueno, Masaru and Uchiumi, Tetsuya},
	month = aug,
	year = {2024},
	note = {arXiv:2408.11428 [cs]},
	keywords = {Computer Science - Software Engineering},
	file = {PDF:/Users/rasztabigab/Zotero/storage/LXZXIS4K/Ueno and Uchiumi - 2024 - Migrating Existing Container Workload to Kubernetes -- LLM Based Approach and Evaluation.pdf:application/pdf},
}

@inproceedings{kratzke_dont_2024,
	address = {Angers, France},
	title = {Don't {Train}, {Just} {Prompt}: {Towards} a {Prompt} {Engineering} {Approach} for a {More} {Generative} {Container} {Orchestration} {Management}:},
	isbn = {978-989-758-701-6},
	shorttitle = {Don't {Train}, {Just} {Prompt}},
	url = {https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0012710300003711},
	doi = {10.5220/0012710300003711},
	abstract = {Background: The intricate architecture of container orchestration systems like Kubernetes relies on the critical role of declarative manifest ﬁles that serve as the blueprints for orchestration. However, managing these manifest ﬁles often presents complex challenges requiring signiﬁcant DevOps expertise. Methodology: This position paper explores using Large Language Models (LLMs) to automate the generation of Kubernetes manifest ﬁles through natural language speciﬁcations and prompt engineering, aiming to simplify Kubernetes management. The study evaluates these LLMs using Zero-Shot, Few-Shot, and Prompt-Chaining techniques against DevOps requirements and the ability to support fully automated deployment pipelines. Results show that LLMs can produce Kubernetes manifests with varying degrees of manual intervention, with GPT-4 and GPT-3.5 showing potential for fully automated deployments. Interestingly, smaller models sometimes outperform larger ones, questioning the assumption that bigger is always better. Conclusion: The study emphasizes that prompt engineering is critical to optimizing LLM outputs for Kubernetes. It suggests further research into prompt strategies and LLM comparisons and highlights a promising research direction for integrating LLMs into automatic deployment pipelines.},
	language = {en},
	urldate = {2025-01-23},
	booktitle = {Proceedings of the 14th {International} {Conference} on {Cloud} {Computing} and {Services} {Science}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Kratzke, Nane and Drews, André},
	year = {2024},
	pages = {248--256},
	file = {PDF:/Users/rasztabigab/Zotero/storage/AXC6FJA9/Kratzke and Drews - 2024 - Don't Train, Just Prompt Towards a Prompt Engineering Approach for a More Generative Container Orch.pdf:application/pdf},
}

@inproceedings{lanciano_analyzing_2023,
	address = {Prague, Czech Republic},
	title = {Analyzing {Declarative} {Deployment} {Code} with {Large} {Language} {Models}:},
	isbn = {978-989-758-650-7},
	shorttitle = {Analyzing {Declarative} {Deployment} {Code} with {Large} {Language} {Models}},
	url = {https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0011991200003488},
	doi = {10.5220/0011991200003488},
	abstract = {In the cloud-native era, developers have at their disposal an unprecedented landscape of services to build scalable distributed systems. The DevOps paradigm emerged as a response to the increasing necessity of better automations, capable of dealing with the complexity of modern cloud systems. For instance, Infrastructure-asCode tools provide a declarative way to deﬁne, track, and automate changes to the infrastructure underlying a cloud application. Assuring the quality of this part of a code base is of utmost importance. However, learning to produce robust deployment speciﬁcations is not an easy feat, and for the domain experts it is timeconsuming to conduct code-reviews and transfer the appropriate knowledge to novice members of the team. Given the abundance of data generated throughout the DevOps cycle, machine learning (ML) techniques seem a promising way to tackle this problem. In this work, we propose an approach based on Large Language Models to analyze declarative deployment code and automatically provide QA-related recommendations to developers, such that they can beneﬁt of established best practices and design patterns. We developed a prototype of our proposed ML pipeline, and empirically evaluated our approach on a collection of Kubernetes manifests exported from a repository of internal projects at Nokia Bell Labs.},
	language = {en},
	urldate = {2025-01-23},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Cloud} {Computing} and {Services} {Science}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Lanciano, Giacomo and Stein, Manuel and Hilt, Volker and Cucinotta, Tommaso},
	year = {2023},
	pages = {289--296},
	file = {PDF:/Users/rasztabigab/Zotero/storage/DNJ6HQGE/Lanciano et al. - 2023 - Analyzing Declarative Deployment Code with Large Language Models.pdf:application/pdf},
}

@inproceedings{pujar_invited_2023,
	address = {San Francisco, CA, USA},
	title = {Invited: {Automated} {Code} generation for {Information} {Technology} {Tasks} in {YAML} through {Large} {Language} {Models}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {9798350323481},
	shorttitle = {Invited},
	url = {https://ieeexplore.ieee.org/document/10247987/},
	doi = {10.1109/DAC56929.2023.10247987},
	abstract = {The recent improvement in code generation capabilities due to the use of large language models has mainly beneﬁted general purpose programming languages. Domain speciﬁc languages, such as the ones used for IT Automation, received far less attention, despite involving many active developers and being an essential component of modern cloud platforms. This work focuses on the generation of Ansible YAML, a widely used markup language for IT Automation. We present Ansible Wisdom, a natural-language to Ansible YAML code generation tool, aimed at improving IT automation productivity. Results show that Ansible Wisdom can accurately generate Ansible script from natural language prompts with performance comparable or better than existing state of the art code generation models.},
	language = {en},
	urldate = {2025-01-23},
	booktitle = {2023 60th {ACM}/{IEEE} {Design} {Automation} {Conference} ({DAC})},
	publisher = {IEEE},
	author = {Pujar, Saurabh and Buratti, Luca and Guo, Xiaojie and Dupuis, Nicolas and Lewis, Burn and Suneja, Sahil and Sood, Atin and Nalawade, Ganesh and Jones, Matt and Morari, Alessandro and Puri, Ruchir},
	month = jul,
	year = {2023},
	pages = {1--4},
	file = {PDF:/Users/rasztabigab/Zotero/storage/F77VRJ2R/Pujar et al. - 2023 - Invited Automated Code generation for Information Technology Tasks in YAML through Large Language M.pdf:application/pdf},
}

@misc{hu_llm-based_2025,
	title = {An {LLM}-based {Agent} for {Reliable} {Docker} {Environment} {Configuration}},
	url = {http://arxiv.org/abs/2502.13681},
	doi = {10.48550/arXiv.2502.13681},
	abstract = {Environment configuration is a critical yet time-consuming step in software development, especially when dealing with unfamiliar code repositories. While Large Language Models (LLMs) demonstrate the potential to accomplish software engineering tasks, existing methods for environment configuration often rely on manual efforts or fragile scripts, leading to inefficiencies and unreliable outcomes. We introduce Repo2Run, the first LLM-based agent designed to fully automate environment configuration and generate executable Dockerfiles for arbitrary Python repositories. We address two major challenges: (1) enabling the LLM agent to configure environments within isolated Docker containers, and (2) ensuring the successful configuration process is recorded and accurately transferred to a Dockerfile without error. To achieve this, we propose atomic configuration synthesis, featuring a dual-environment architecture (internal and external environment) with a rollback mechanism to prevent environment “pollution” from failed commands, guaranteeing atomic execution (execute fully or not at all) and a Dockerfile generator to transfer successful configuration steps into runnable Dockerfiles. We evaluate Repo2Run on our proposed benchmark of 420 recent Python repositories with unit tests, where it achieves an 86.0\% success rate, outperforming the best baseline by 63.9\%. Repo2Run is available at https://github.com/bytedance/Repo2Run.},
	language = {en},
	urldate = {2025-03-31},
	publisher = {arXiv},
	author = {Hu, Ruida and Peng, Chao and Wang, Xinchen and Gao, Cuiyun},
	month = mar,
	year = {2025},
	note = {arXiv:2502.13681 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Software Engineering, Computer Science - Artificial Intelligence},
	file = {PDF:/Users/rasztabigab/Zotero/storage/LB7XG52V/Hu et al. - 2025 - An LLM-based Agent for Reliable Docker Environment Configuration.pdf:application/pdf},
}

@misc{srivatsa_survey_2024,
	title = {A {Survey} of using {Large} {Language} {Models} for {Generating} {Infrastructure} as {Code}},
	url = {http://arxiv.org/abs/2404.00227},
	doi = {10.48550/arXiv.2404.00227},
	abstract = {Infrastructure as Code (IaC) is a revolutionary approach which has gained significant prominence in the Industry. IaC manages and provisions IT infrastructure using machinereadable code by enabling automation, consistency across the environments, reproducibility, version control, error reduction and enhancement in scalability. However, IaC orchestration is often a painstaking effort which requires specialised skills as well as a lot of manual effort. Automation of IaC is a necessity in the present conditions of the Industry and in this survey, we study the feasibility of applying Large Language Models (LLM) to address this problem. LLMs are large neural network-based models which have demonstrated significant language processing abilities and shown to be capable of following a range of instructions within a broad scope. Recently, they have also been adapted for code understanding and generation tasks successfully, which makes them a promising choice for the automatic generation of IaC configurations. In this survey, we delve into the details of IaC, usage of IaC in different platforms, their challenges, LLMs in terms of code-generation aspects and the importance of LLMs in IaC along with our own experiments. Finally, we conclude by presenting the challenges in this area and highlighting the scope for future research.},
	language = {en},
	urldate = {2025-03-31},
	publisher = {arXiv},
	author = {Srivatsa, Kalahasti Ganesh and Mukhopadhyay, Sabyasachi and Katrapati, Ganesh and Shrivastava, Manish},
	month = mar,
	year = {2024},
	note = {arXiv:2404.00227 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Software Engineering},
	file = {PDF:/Users/rasztabigab/Zotero/storage/MDY23SUQ/Srivatsa et al. - 2024 - A Survey of using Large Language Models for Generating Infrastructure as Code.pdf:application/pdf},
}

@article{kon_iac-eval_nodate,
	title = {{IaC}-{Eval}: {A} {Code} {Generation} {Benchmark} for {Cloud} {Infrastructure}-as-{Code} {Programs}},
	abstract = {Infrastructure-as-Code (IaC), an important component of cloud computing, allows the definition of cloud infrastructure in high-level programs. However, developing IaC programs is challenging, complicated by factors that include the burgeoning complexity of the cloud ecosystem (e.g., diversity of cloud services and workloads), and the relative scarcity of IaC-specific code examples and public repositories. While large language models (LLMs) have shown promise in general code generation and could potentially aid in IaC development, no benchmarks currently exist for evaluating their ability to generate IaC code. We present IaC-Eval, a first step in this research direction. IaC-Eval’s dataset includes 458 human-curated scenarios covering a wide range of popular AWS services, at varying difficulty levels. Each scenario mainly comprises a natural language IaC problem description and an infrastructure intent specification. The former is fed as user input to the LLM, while the latter is a general notion used to verify if the generated IaC program conforms to the user’s intent; by making explicit the problem’s requirements that can encompass various cloud services, resources and internal infrastructure details. Our in-depth evaluation shows that contemporary LLMs perform poorly on IaC-Eval, with the top-performing model, GPT-4, obtaining a pass@1 accuracy of 19.36\%. In contrast, it scores 86.6\% on EvalPlus, a popular Python code generation benchmark, highlighting a need for advancements in this domain. We open-source the IaC-Eval dataset and evaluation framework at https://github.com/autoiac-project/iac-eval to enable future research on LLM-based IaC code generation.},
	language = {en},
	author = {Kon, Patrick Tser Jern and Liu, Jiachen and Qiu, Yiming and Fan, Weijun and He, Ting and Lin, Lei and Zhang, Haoran and Park, Owen M and Elengikal, George S and Kang, Yuxin and Chen, Ang and Chowdhury, Mosharaf and Lee, Myungjin and Wang, Xinyu},
	file = {PDF:/Users/rasztabigab/Zotero/storage/2LCEBURH/Kon et al. - IaC-Eval A Code Generation Benchmark for Cloud Infrastructure-as-Code Programs.pdf:application/pdf},
}

@inproceedings{low_repairing_2024,
	address = {Pittsburgh, PA, USA},
	title = {Repairing {Infrastructure}-as-{Code} using {Large} {Language} {Models}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {9798350391930},
	url = {https://ieeexplore.ieee.org/document/10734039/},
	doi = {10.1109/SecDev61143.2024.00008},
	abstract = {Infrastructure-as-Code (IaC) is the practice of provisioning and managing cloud resources using machine-readable code. IaC is seeing increased adoption because it enhances transparency and reliability of infrastructure operations. However, as any software code, IaC can also contain misconﬁgurations, which can lead to insecure infrastructure, which may result in data breaches. Existing IaC scanning tools are able to detect common misconﬁgurations in IaC but they require IaC developers to manually repair the code. Recent advances in Large Language Models (LLMs) have led to promising results in applying LLMs to Automatic Program Repair (APR) tasks for code written in different languages. In this work, we propose an LLM-based approach to ﬁx misconﬁgurations in IaC code. After misconﬁgurations in IaC code are identiﬁed by scanning tools, we feed the LLMs with the IaC code, details about the misconﬁgurations, and additional context provided by a human-in-the-loop and prompt the LLM to generate the repaired IaC code. We tested our approach on several vulnerable IaC repositories and found that the GPT-4 model from OpenAI suggests ﬁxes that reduce up to 84.7\% of the misconﬁguration alarms produced by the scanners and our two-pass solution signiﬁcantly improves the performance over a one-pass only approach. However, of the ﬁxes suggested, we manually determined that only 79.6\% actually solve the problem, while the remaining 20.4\% are hallucinated ﬁxes. Speciﬁcally, LLM hallucinations in the generated outputs pass checks for misconﬁgurations but fail other syntax and schema validation checks or do not address the underlying security issue. We propose a few potential approaches to tackle this challenge.},
	language = {en},
	urldate = {2025-03-31},
	booktitle = {2024 {IEEE} {Secure} {Development} {Conference} ({SecDev})},
	publisher = {IEEE},
	author = {Low, En and Cheh, Carmen and Chen, Binbin},
	month = oct,
	year = {2024},
	pages = {20--27},
	file = {PDF:/Users/rasztabigab/Zotero/storage/65ZKZ3MJ/Low et al. - 2024 - Repairing Infrastructure-as-Code using Large Language Models.pdf:application/pdf},
}

@misc{fu_security_2025,
	title = {Security {Weaknesses} of {Copilot}-{Generated} {Code} in {GitHub} {Projects}: {An} {Empirical} {Study}},
	shorttitle = {Security {Weaknesses} of {Copilot}-{Generated} {Code} in {GitHub} {Projects}},
	url = {http://arxiv.org/abs/2310.02059},
	doi = {10.48550/arXiv.2310.02059},
	abstract = {YUJIA FU, School of Computer Science, Wuhan University, China PENG LIANG∗, School of Computer Science, Wuhan University, China AMJED TAHIR, Massey University, New Zealand ZENGYANG LI, School of Computer Science, Central China Normal University, China MOJTABA SHAHIN, RMIT University, Australia JIAXIN YU, School of Computer Science, Wuhan University, China JINFU CHEN, School of Computer Science, Wuhan University, China Modern code generation tools utilizing AI models like Large Language Models (LLMs) have gained increased popularity due to their ability to produce functional code. However, their usage presents security challenges, often resulting in insecure code merging into the code base. Thus, evaluating the quality of generated code, especially its security, is crucial. While prior research explored various aspects of code generation, the focus on security has been limited, mostly examining code produced in controlled environments rather than open source development scenarios. To address this gap, we conducted an empirical study, analyzing code snippets generated by GitHub Copilot and two other AI code generation tools (i.e., CodeWhisperer and Codeium) from GitHub projects. Our analysis identified 733 snippets, revealing a high likelihood of security weaknesses, with 29.5\% of Python and 24.2\% of JavaScript snippets affected. These issues span 43 Common Weakness Enumeration (CWE) categories, including significant ones like CWE-330: Use of Insufficiently Random Values, CWE-94: Improper Control of Generation of Code, and CWE-79: Cross-site Scripting. Notably, eight of those CWEs are among the 2023 CWE Top-25, highlighting their severity. We further examined using Copilot Chat to fix security issues in Copilot-generated code by providing Copilot Chat with warning messages from the static analysis tools, and up to 55.5\% of the security issues can be fixed. We finally provide the suggestions for mitigating security issues in generated code. CCS Concepts: • Software and its engineering → Software development techniques; • Security and privacy → Software security engineering.},
	language = {en},
	urldate = {2025-03-31},
	publisher = {arXiv},
	author = {Fu, Yujia and Liang, Peng and Tahir, Amjed and Li, Zengyang and Shahin, Mojtaba and Yu, Jiaxin and Chen, Jinfu},
	month = feb,
	year = {2025},
	note = {arXiv:2310.02059 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Software Engineering},
	file = {PDF:/Users/rasztabigab/Zotero/storage/6SMHPY4D/Fu et al. - 2025 - Security Weaknesses of Copilot-Generated Code in GitHub Projects An Empirical Study.pdf:application/pdf},
}

@misc{liu_prompt_2024,
	title = {Prompt {Injection} attack against {LLM}-integrated {Applications}},
	url = {http://arxiv.org/abs/2306.05499},
	doi = {10.48550/arXiv.2306.05499},
	abstract = {Large Language Models (LLMs), renowned for their superior proficiency in language comprehension and generation, stimulate a vibrant ecosystem of applications around them. However, their extensive assimilation into various services introduces significant security risks. This study deconstructs the complexities and implications of prompt injection attacks on actual LLM-integrated applications. Initially, we conduct an exploratory analysis on ten commercial applications, highlighting the constraints of current attack strategies in practice. Prompted by these limitations, we subsequently formulate HOUYI, a novel black-box prompt injection attack technique, which draws inspiration from traditional web injection attacks. HOUYI is compartmentalized into three crucial elements: a seamlessly-incorporated pre-constructed prompt, an injection prompt inducing context partition, and a malicious payload designed to fulfill the attack objectives. Leveraging HOUYI, we unveil previously unknown and severe attack outcomes, such as unrestricted arbitrary LLM usage and uncomplicated application prompt theft. We deploy HOUYI on 36 actual LLM-integrated applications and discern 31 applications susceptible to prompt injection. 10 vendors have validated our discoveries, including Notion, which has the potential to impact millions of users. Our investigation illuminates both the possible risks of prompt injection attacks and the possible tactics for mitigation.},
	language = {en},
	urldate = {2025-03-31},
	publisher = {arXiv},
	author = {Liu, Yi and Deng, Gelei and Li, Yuekang and Wang, Kailong and Wang, Zihao and Wang, Xiaofeng and Zhang, Tianwei and Liu, Yepang and Wang, Haoyu and Zheng, Yan and Liu, Yang},
	month = mar,
	year = {2024},
	note = {arXiv:2306.05499 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Cryptography and Security, Computer Science - Software Engineering, Computer Science - Artificial Intelligence},
	file = {PDF:/Users/rasztabigab/Zotero/storage/494GYLID/Liu et al. - 2024 - Prompt Injection attack against LLM-integrated Applications.pdf:application/pdf},
}
