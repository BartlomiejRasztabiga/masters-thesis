% Artykuł w recenzowanym czasopiśmie.
@article{szczypiorski2015,
    author    = {Szczypiorski, K. and Janicki, A. and Wendzel, S},
    title     = {{T}he {G}ood, {T}he {B}ad {A}nd {T}he {U}gly: {E}valuation of {W}i-{F}i {S}teganography},
    journal   = {Journal of Communications},
    volume    = {10},
    number    = {10},
    pages     = {747--752},
    publisher = {Journal of Communications (JCM)},
    year      = {2015}
}

% Książka.
@book{goossens93,
    author    = {Michel Goossens and Frank Mittelbach and Alexander Samarin},
    title     = {The LaTeX Companion},
    publisher = {Addison-Wesley},
    address   = {Reading, Massachusetts},
    year      = {1993}
}

% Fragment książki (np. zakres stron).
@inbook{wang97,
    author    = {Hao Wang},
    title     = {A Logical Journey: From G{\"o}del to Philosophy.},
    publisher = {A Bradford Book},
    pages     = {316},
    year      = {1997}
}

% Fragment książki (np. esej), posiadający własny tytuł.
@incollection{goedel95,
    author    = {Kurt G{\"o}del},
    title     = {Texts relating to the ontological proof},
    booktitle = {Unpublished Essays and Lectures},
    publisher = {Oxford University Press},
    pages     = {429--437},
    year      = {1995}
}

% Publikacja konferencyjna.
@inproceedings{benzmuller2014,
    author       = {{Ch}. Benzmuller and B. W. Paleo},
    title        = {Automating {G\"o}del’s {O}ntological {P}roof of {G}od’s {E}xistence with {H}igher-order {A}utomated {T}heorem {P}rovers},
    booktitle    = {European	Conference on Artificial Intelligence},
    publisher    = {IOS Press},
    howpublished = {Dostęp zdalny (10.04.2019): \url{http://page.mi.fu-berlin.de/cbenzmueller/papers/C40.pdf}},
    year         = {2014}
}

% Raport techniczny.
@techreport{duqu2011,
    author      = {Bencsáth, B. and Pék, G. and Buttyán, L. and Félegyházi M.},
    title       = {{D}uqu: {A} {S}tuxnet-like malware found in the wild},
    institution = {Laboratory of Cryptography and System Security, Hungary},
    year        = {2011}
}

% Specyfikacja techniczna.
@manual{shs2015,
    title        = {{FIPS} 180-4: {S}ecure {H}ash {S}tandard ({SHS})},
    howpublished = {Dostęp zdalny (13.03.2019): \url{https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf}},
    year         = {2015}
}

% Praca magisterska.
@mastersthesis{wozniak2018,
    author = {Woźniak, Piotr},
    title  = {{P}rogramowanie kwadratowe w usuwaniu efektu rozmycia ruchu w fotografii cyfrowej},
    school = {Wydział Elektroniki i Technik Informacyjnych, Politechnika Warszawska},
    year   = {2018}
}

% Nieopublikowany artykuł, dostępny np. tylko w internecie.
@unpublished{koons2005,
    author = {Koons, Robert C.},
    title  = {{S}obel on {G\"o}del’s {O}ntological {P}roof},
    note   = {Dostęp zdalny (25.04.2019): \url{http://www.robkoons.net/media/69b0dd04a9d2fc6dffff80b4ffffd524.pdf}},
    year   = {2005}
}

% Źródło innego typu, np. repozytorium na GitHubie.
@misc{dcp19,
    author       = {Brodzki, Artur M.},
    title        = {{I}mplementation of own steganography protocol {DCP}-19, loosely based on {HICCUPS}},
    howpublished = {Dostęp zdalny (14.03.2019): \url{https://github.com/ArturB/DCP-19}},
    year         = {2019}
}

% MOJE


@misc{malul_genkubesec_2024,
	title = {{GenKubeSec}: {LLM}-{Based} {Kubernetes} {Misconfiguration} {Detection}, {Localization}, {Reasoning}, and {Remediation}},
	shorttitle = {{GenKubeSec}},
	url = {http://arxiv.org/abs/2405.19954},
	doi = {10.48550/arXiv.2405.19954},
	abstract = {A key challenge associated with Kubernetes configuration files (KCFs) is that they are often highly complex and error-prone, leading to security vulnerabilities and operational setbacks. Rule-based (RB) tools for KCF misconfiguration detection rely on static rule sets, making them inherently limited and unable to detect newlydiscovered misconfigurations. RB tools also suffer from misdetection, since mistakes are likely when coding the detection rules. Recent methods for detecting and remediating KCF misconfigurations are limited in terms of their scalability and detection coverage, or due to the fact that they have high expertise requirements and do not offer automated remediation along with misconfiguration detection. Novel approaches that employ LLMs in their pipeline rely on API-based, general-purpose, and mainly commercial models. Thus, they pose security challenges, have inconsistent classification performance, and can be costly. In this paper, we propose GenKubeSec, a comprehensive and adaptive, LLM-based method, which, in addition to detecting a wide variety of KCF misconfigurations, also identifies the exact location of the misconfigurations and provides detailed reasoning about them, along with suggested remediation. When empirically compared with three industry-standard RB tools, GenKubeSec achieved equivalent precision (0.990 ± 0.020) and superior recall (0.999 ± 0.026). When a random sample of KCFs was examined by a Kubernetes security expert, GenKubeSec’s explanations as to misconfiguration localization, reasoning and remediation were 100\% correct, informative and useful. To facilitate further advancements in this domain, we share the unique dataset we collected, a unified misconfiguration index we developed for label standardization, our experimentation code, and GenKubeSec itself as an open-source tool. A video demonstrating our implementation of GenKubeSec can be found here: https://youtu.be/hBehYfdR-zM.},
	language = {en},
	urldate = {2025-01-23},
	publisher = {arXiv},
	author = {Malul, Ehud and Meidan, Yair and Mimran, Dudu and Elovici, Yuval and Shabtai, Asaf},
	month = may,
	year = {2024},
	note = {arXiv:2405.19954 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Cryptography and Security, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning},
	file = {PDF:/Users/rasztabigab/Zotero/storage/WDKEZU97/Malul et al. - 2024 - GenKubeSec LLM-Based Kubernetes Misconfiguration Detection, Localization, Reasoning, and Remediatio.pdf:application/pdf},
}

@misc{ueno_migrating_2024,
	title = {Migrating {Existing} {Container} {Workload} to {Kubernetes} -- {LLM} {Based} {Approach} and {Evaluation}},
	url = {http://arxiv.org/abs/2408.11428},
	doi = {10.48550/arXiv.2408.11428},
	abstract = {Although Kubernetes has become a widespread open-source system that automates the management of containerized applications, its complexity can be a significant barrier, particularly for application developers unfamiliar with it. One approach employs large language models (LLMs) to assist developers in generating Kubernetes manifests; however it is currently impossible to determine whether the output satisfies given specifications and is comprehensible. In this study, we proposed a benchmarking method for evaluating the effectiveness of LLMs in synthesizing manifests, using the Compose specification — a standard widely adopted by application developers — as input. The proposed benchmarking method revealed that LLMs generally produce accurate results that compensate for simple specification gaps. However, we also observed that inline comments for readability were often omitted, and completion accuracy was low for atypical inputs with unclear intentions.},
	language = {en},
	urldate = {2025-01-23},
	publisher = {arXiv},
	author = {Ueno, Masaru and Uchiumi, Tetsuya},
	month = aug,
	year = {2024},
	note = {arXiv:2408.11428 [cs]},
	keywords = {Computer Science - Software Engineering},
	file = {PDF:/Users/rasztabigab/Zotero/storage/LXZXIS4K/Ueno and Uchiumi - 2024 - Migrating Existing Container Workload to Kubernetes -- LLM Based Approach and Evaluation.pdf:application/pdf},
}

@inproceedings{kratzke_dont_2024,
	address = {Angers, France},
	title = {Don't {Train}, {Just} {Prompt}: {Towards} a {Prompt} {Engineering} {Approach} for a {More} {Generative} {Container} {Orchestration} {Management}:},
	isbn = {978-989-758-701-6},
	shorttitle = {Don't {Train}, {Just} {Prompt}},
	url = {https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0012710300003711},
	doi = {10.5220/0012710300003711},
	abstract = {Background: The intricate architecture of container orchestration systems like Kubernetes relies on the critical role of declarative manifest ﬁles that serve as the blueprints for orchestration. However, managing these manifest ﬁles often presents complex challenges requiring signiﬁcant DevOps expertise. Methodology: This position paper explores using Large Language Models (LLMs) to automate the generation of Kubernetes manifest ﬁles through natural language speciﬁcations and prompt engineering, aiming to simplify Kubernetes management. The study evaluates these LLMs using Zero-Shot, Few-Shot, and Prompt-Chaining techniques against DevOps requirements and the ability to support fully automated deployment pipelines. Results show that LLMs can produce Kubernetes manifests with varying degrees of manual intervention, with GPT-4 and GPT-3.5 showing potential for fully automated deployments. Interestingly, smaller models sometimes outperform larger ones, questioning the assumption that bigger is always better. Conclusion: The study emphasizes that prompt engineering is critical to optimizing LLM outputs for Kubernetes. It suggests further research into prompt strategies and LLM comparisons and highlights a promising research direction for integrating LLMs into automatic deployment pipelines.},
	language = {en},
	urldate = {2025-01-23},
	booktitle = {Proceedings of the 14th {International} {Conference} on {Cloud} {Computing} and {Services} {Science}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Kratzke, Nane and Drews, André},
	year = {2024},
	pages = {248--256},
	file = {PDF:/Users/rasztabigab/Zotero/storage/AXC6FJA9/Kratzke and Drews - 2024 - Don't Train, Just Prompt Towards a Prompt Engineering Approach for a More Generative Container Orch.pdf:application/pdf},
}

@inproceedings{lanciano_analyzing_2023,
	address = {Prague, Czech Republic},
	title = {Analyzing {Declarative} {Deployment} {Code} with {Large} {Language} {Models}:},
	isbn = {978-989-758-650-7},
	shorttitle = {Analyzing {Declarative} {Deployment} {Code} with {Large} {Language} {Models}},
	url = {https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0011991200003488},
	doi = {10.5220/0011991200003488},
	abstract = {In the cloud-native era, developers have at their disposal an unprecedented landscape of services to build scalable distributed systems. The DevOps paradigm emerged as a response to the increasing necessity of better automations, capable of dealing with the complexity of modern cloud systems. For instance, Infrastructure-asCode tools provide a declarative way to deﬁne, track, and automate changes to the infrastructure underlying a cloud application. Assuring the quality of this part of a code base is of utmost importance. However, learning to produce robust deployment speciﬁcations is not an easy feat, and for the domain experts it is timeconsuming to conduct code-reviews and transfer the appropriate knowledge to novice members of the team. Given the abundance of data generated throughout the DevOps cycle, machine learning (ML) techniques seem a promising way to tackle this problem. In this work, we propose an approach based on Large Language Models to analyze declarative deployment code and automatically provide QA-related recommendations to developers, such that they can beneﬁt of established best practices and design patterns. We developed a prototype of our proposed ML pipeline, and empirically evaluated our approach on a collection of Kubernetes manifests exported from a repository of internal projects at Nokia Bell Labs.},
	language = {en},
	urldate = {2025-01-23},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Cloud} {Computing} and {Services} {Science}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Lanciano, Giacomo and Stein, Manuel and Hilt, Volker and Cucinotta, Tommaso},
	year = {2023},
	pages = {289--296},
	file = {PDF:/Users/rasztabigab/Zotero/storage/DNJ6HQGE/Lanciano et al. - 2023 - Analyzing Declarative Deployment Code with Large Language Models.pdf:application/pdf},
}

@inproceedings{pujar_invited_2023,
	address = {San Francisco, CA, USA},
	title = {Invited: {Automated} {Code} generation for {Information} {Technology} {Tasks} in {YAML} through {Large} {Language} {Models}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {9798350323481},
	shorttitle = {Invited},
	url = {https://ieeexplore.ieee.org/document/10247987/},
	doi = {10.1109/DAC56929.2023.10247987},
	abstract = {The recent improvement in code generation capabilities due to the use of large language models has mainly beneﬁted general purpose programming languages. Domain speciﬁc languages, such as the ones used for IT Automation, received far less attention, despite involving many active developers and being an essential component of modern cloud platforms. This work focuses on the generation of Ansible YAML, a widely used markup language for IT Automation. We present Ansible Wisdom, a natural-language to Ansible YAML code generation tool, aimed at improving IT automation productivity. Results show that Ansible Wisdom can accurately generate Ansible script from natural language prompts with performance comparable or better than existing state of the art code generation models.},
	language = {en},
	urldate = {2025-01-23},
	booktitle = {2023 60th {ACM}/{IEEE} {Design} {Automation} {Conference} ({DAC})},
	publisher = {IEEE},
	author = {Pujar, Saurabh and Buratti, Luca and Guo, Xiaojie and Dupuis, Nicolas and Lewis, Burn and Suneja, Sahil and Sood, Atin and Nalawade, Ganesh and Jones, Matt and Morari, Alessandro and Puri, Ruchir},
	month = jul,
	year = {2023},
	pages = {1--4},
	file = {PDF:/Users/rasztabigab/Zotero/storage/F77VRJ2R/Pujar et al. - 2023 - Invited Automated Code generation for Information Technology Tasks in YAML through Large Language M.pdf:application/pdf},
}
