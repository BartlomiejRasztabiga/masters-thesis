\clearpage % Rozdziały zaczynamy od nowej strony.
\section{Projekt eksperymentów}

Cel: Szczegółowe przedstawienie projektu eksperymentów mających na celu ocenę zdolności dużych modeli językowych (LLM) do automatycznego generowania konfiguracji Infrastructure as Code (IaC) dla środowisk Docker i Kubernetes.

Proponowana zawartość:

\textbf{Cel i hipotezy badawcze:}
Sformułowanie głównego celu eksperymentów.
Wypunktowanie konkretnych hipotez badawczych do weryfikacji.
\textbf{Zestawienie przypadków testowych:}
Opis 4 spreparowanych repozytoriów, reprezentujących różne scenariusze wdrożeniowe:
Aplikacja bezstanowa bez zależności.
Aplikacja wykorzystująca stanową bazę danych postawioną obok.
Frontend + Backend + Baza Danych.
Prosty system mikroserwisowy.
Zostawienie miejsca na wspomnienie o ewentualnym wykorzystaniu dodatkowych repozytoriów z serwisu GitHub w celu przetestowania działania na "niespreparowanych" aplikacjach.
\textbf{Metodyka generacji i promptowania:}
Szczegółowy opis, że metodą promptowania będzie agent napisany w LangGraph.
Miejsce na wykorzystywany prompt (listing lub szczegółowy opis struktury).
Miejsce na opis narzędzi (funkcji), które będą dostępne dla agenta i które będzie mógł wykorzystać (np. do czytania plików, walidacji składni, itp.).
\textbf{Proces testowy:}
Szczegółowy schemat działania agenta i następującego po nim procesu oceny: \begin{enumerate} \item Przygotowanie środowiska roboczego (working directory). \item Sklonowanie repozytorium aplikacji. \item Generowanie Dockerfile (lub wielu, w zależności od architektury) przez agenta LLM. \item Generowanie manifestów Kubernetes przez agenta LLM. \end{enumerate}
W tym momencie kończy się rola generowania przez agenta, a zaczyna rola automatycznej oceny modelu (jakość generacji): \begin{enumerate}[resume] \item Weryfikacja syntaktycznej poprawności wygenerowanego Dockerfile. \item Statyczna analiza Dockerfile za pomocą Hadolint (sprawdzenie "prucia się" Hadolint). \item Próba budowy obrazu Docker na podstawie wygenerowanego Dockerfile. \item Weryfikacja syntaktycznej poprawności wygenerowanych manifestów Kubernetes. \item Statyczna analiza manifestów Kubernetes za pomocą Kube-linter (sprawdzenie "prucia się" Kube-linter). \item Próba zaaplikowania manifestów Kubernetes w środowisku Kind. \item Walidacja działania aplikacji w środowisku Kubernetes (walidacja runtime). \item Ocena jakości konfiguracji pod kątem dobrych praktyk (np. poprzez interpretację wyników statycznej analizy). \end{enumerate}
\textbf{Kryteria oceny i metryki:}
Definicja kryteriów jakości IaC (poprawność składniowa/funkcjonalna, bezpieczeństwo, kompletność, deterministyczność, odporność na manipulacje, wydajność generacji).
Wskazanie, jakie metryki będą używane do pomiaru każdego kryterium.
\textbf{Przykładowe obserwacje i napotkane problemy:}
Omówienie ogólnego zachowania modeli LLM podczas generacji.
Analiza typowych problemów napotkanych podczas eksperymentów (np. ograniczenia tokenów, błędy w kontekście, wpływ długości promptów, deterministyczność).
Wyniki szczegółowe zostaną zaprezentowane w kolejnym rozdziale.

TODO napisac ze wszystkie modele dostaja ten sam prompt i sa testowane na tych samych repozytoriach, a wyniki sa porownywane miedzy nimi.

TODO co bedzie mierzone i jak? (np langsmith), np. liczba tokenow wejsciowych, wyjsciowych, liczba przeczytanych plikow, liczba wylistowan plikow, liczbe bledow statycznej analizy itd

TODO