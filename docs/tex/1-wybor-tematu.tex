\clearpage % Rozdziały zaczynamy od nowej strony.
\section{Wybór tematu}


\subsection{Tytuł pracy}
Zastosowanie dużych modeli językowych (LLM) do generowania konfiguracji Docker i Kubernetes

\subsection{Opis tematu}
Celem niniejszej pracy jest analiza możliwości zastosowania dużych modeli językowych (LLM) do generowania konfiguracji Dockerfile i Kubernetes w ramach platformy jako usługi (PaaS) służącej do budowania i wdrażania aplikacji w klastrze Kubernetes. W pracy zostanie przeprowadzona ocena dostępnych modeli, takich jak GPT, LLAMA, Falcon czy Claude, pod kątem ich zdolności do poprawnego i bezpiecznego tworzenia tych konfiguracji. Szczególny nacisk zostanie położony na analizę aspektów bezpieczeństwa wygenerowanych konfiguracji, takich jak podatność na ataki (np. pozwalające na wykonanie arbitralnego kodu) czy możliwość "jailbreakingu" modelu poprzez manipulację danymi wejściowymi. Planowane jest opracowanie metodologii porównawczej dla wybranych modeli oraz przeprowadzenie testów poprawności, wydajności i bezpieczeństwa. Wynikiem pracy będzie system PaaS, który automatycznie generuje konfiguracje dla podanego repozytorium kodu oraz na ich podstawie buduje i wdraża aplikacje.

\subsection{Motywacja}
Duże modele językowe (LLM) w ostatnich latach zyskały ogromną popularność, co otwiera wiele nowych możliwości ich zastosowania w różnych dziedzinach. Ich zdolności w zakresie przetwarzania języka naturalnego sprawiają, że mogą być użyteczne również w generowaniu takich technicznych i żmudnych elementów jak konfiguracje Dockerfile czy Kubernetes. Proces ten, wymagający zazwyczaj manualnej pracy DevOpsów, może zostać znacznie uproszczony i przyspieszony dzięki automatyzacji opartej na LLM.

Kolejnym istotnym aspektem jest możliwość wykorzystania repozytorium kodu jako wejścia dla modeli LLM. Takie podejście rodzi wiele pytań badawczych, szczególnie w zakresie podatności generowanych konfiguracji na potencjalne ataki (np. wykonanie arbitralnego kodu czy "jailbreaking" modeli). Bezpieczeństwo wygenerowanych konfiguracji jest kluczowym obszarem, wymagającym dogłębnej analizy i testów.

Równie ważny jest koncept determinizmu procesu generowania. Czy konfiguracje wygenerowane przez modele LLM mogą być deterministyczne i pozbawione błędów? Jakie potencjalne "dziury" mogą się pojawić i czy tego rodzaju rozwiązania mogłyby zastąpić człowieka w procesie tworzenia konfiguracji?

Na wybór tego tematu wpłynęły również osobiste zainteresowania autora. DevOps, jako dziedzina łącząca aspekty programistyczne i operacyjne, od zawsze budził jego zainteresowanie. Chęć zgłębienia zastosowań LLM w tym obszarze jest dodatkowym bodźcem do realizacji tej pracy.

