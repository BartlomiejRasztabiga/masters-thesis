\clearpage % Rozdziały zaczynamy od nowej strony.
\section{Opis eksperymentów}

\subsection{Cel eksperymentów}

Eksperymenty miały na celu przeprowadzenie proof of concept (PoC) dla automatycznego generowania konfiguracji Docker i Kubernetes przy użyciu dużych modeli językowych (LLM). Celem było zweryfikowanie, czy modele mogą poprawnie generować pliki konfiguracyjne na podstawie dostarczonego repozytorium kodu, a także zbadanie problemów i wyzwań, których można się spodziewać podczas pisania pracy magisterskiej.

\subsection{Proces eksperymentów}

Algorytm skryptu PoC składał się z następujących kroków:

\begin{enumerate}
    \item Klonowanie repozytorium: Repozytorium projektu było klonowane do lokalnego katalogu tymczasowego.
    \item Analiza struktury repozytorium: Struktura repozytorium była przetwarzana do formatu drzewa plików za pomocą polecenia tree.
    \item Wybór najważniejszych plików: Model LLM otrzymywał strukturę repozytorium i wybierał 5 najważniejszych plików, które mogłyby posłużyć do generowania konfiguracji.
    \item Pobranie zawartości plików: Na podstawie wybranych plików ich zawartość była odczytywana i przygotowywana do wysłania do modelu.
    \item Generowanie pliku Dockerfile: LLM generował plik Dockerfile na podstawie struktury repozytorium i zawartości najważniejszych plików.
    \item Budowanie obrazu Docker: Obraz Docker był budowany lokalnie na podstawie wygenerowanego Dockerfile.
    \item Generowanie konfiguracji Kubernetes: Model LLM generował manifest Kubernetes, zawierający definicje m.in. Deployment, Service i Ingress.
    \item Weryfikacja działania: Wygenerowany obraz Docker był przesyłany do prywatnego rejestru, a manifest Kubernetes wdrażany w klastrze Kubernetes. Działanie aplikacji było potwierdzane uruchomieniem jej na klastrze.
\end{enumerate}


\subsection{Środowisko eksperymentalne}

Testy były przeprowadzone na prywatnym projekcie studenckim z przedmiotu FO (\url(https://github.com/BartlomiejRasztabiga/FO23Z)), zawierającym bezstanową aplikację webową uruchamianą w jednym kontenerze. Najlepsze rezultaty podczas eksperymentów osiągnął model Claude 3.5 Haiku, wykazując się wysoką jakością generowanych plików oraz deterministycznym działaniem. W przeciwieństwie do innych moceli, Claude 3.5 Haiku praktycznie nie generował błędnych konfiguracji - każda inferencja kończyła się przygotowaniem poprawnej konfiguracji.

\subsection{Kod implementacji}

Kod aplikacji obsługującej eksperymenty został zaimplementowany w języku Python z użyciem opisanych wcześniej bibliotek takich jak docker, git i dotenv. Repozytorium z kodem eksperymentu jest dostępne pod adresem: \url{https://gitlab-stud.elka.pw.edu.pl/brasztab/masters-thesis/-/tree/master/poc}

\subsection{Listing prompta uywanego w eksperymentach}

\begin{verbatim}
You are a helpful assistant. You will have 3 use cases, they are listed below,
they're all connected with each other to deliver some bigger value. Use correct 
use_case, first line of the prompt will include name of a use case, e.g.
"get_important_files". Execute only the use case you're asked for. Don't include 
use case name in the response. Don't include
any formatting markers. Return only what you're asked for.

1 (get_important_files): Given repository files structure (only some part of it)
will help to identify the most important files to generate a Dockerfile to build a
valid docker image that can be run to run the app of repository and appropriate 
Kubernetes config (deployments, services, volumes, ingresses) to run it. Choose
only the most important files, required to generate configuration. Respond only 
with the file names, in the same format as provided, ignore formatting markers. 
Use that use case when keyword "get_important_files" is used.

2 (get_dockerfile): Given repository files structure (only some part of it)
and content of the most important files will help to generate a Dockerfile to build
a valid docker image that can be run to run the app of repository. Use latest base 
image versions and best practises, implement all security measures and expose all
necessary ports. Respond only with the content of the Dockerfile, ignore formatting 
markers!!!. Use that use case when keyword "get_dockerfile" is used.

3 (get_k8s_config): Given repository files structure (only some part of it),
content of the most important files and Dockerfile, will help to generate 
appropriate Kubernetes config (deployments, services, volumes, ingresses, etc) to 
run the app of repository. Make sure to use correct ports, defined in the
Dockerfile, to expose services. Use only the resources that are required (e.g. 
don't use pvc if the app doesn't need persistent storage). Use best practises,
implement all security measures and expose all necessary ports. Use provided image
tag. For ingress host, use "rasztabiga.me" as the domain and repository name as
subdomain, not "xxx.local". For example, for repository fo23, resulting domain
should be "fo23.rasztabiga.me". It's very important. Respond only with the content
of the Kubernetes config, ignore formatting markers. Use that use case when keyword 
"get_k8s_config" is used. Don't include regcred. 

You will receive 1000 USD tip, if your results are valid and can be run.

Remember not to use formatting markers in the output, e.g. "```dockerfile" or 
"```yaml".

\end{verbatim}


Prompt został zaprojektowany w taki sposób, aby precyzyjnie kierować działaniem modelu w zależności od kontekstu (wybór plików, generowanie Dockerfile lub konfiguracji Kubernetes).

Prace nad nim zostaną kontynuowane w celu dalszej optymalizacji i usprawnienia procesu generowania konfiguracji.

Szczególnie problematycznym elementem okazała się konieczność wyboru najważniejszych plików z repozytorium, które mogłyby posłużyć do generowania konfiguracji. W przypadku repozytoriów zawierających wiele plików, wybór tych najważniejszych był kluczowym elementem, który mógł wpłynąć na jakość generowanych konfiguracji. Niekiedy 5 plików było zbyt małą próbką, aby model mógł wygenerować poprawne pliki konfiguracyjne. W innych przypadkach, modele wybierały zupełnie bezsensowne pliki, które nie miały związku z konfiguracją aplikacji, a jedynie zwiększały liczbę tokenów w zapytaniu, co mogło wpłynąć na jakość generowanych plików (przez ograniczenie okna kontekstu).