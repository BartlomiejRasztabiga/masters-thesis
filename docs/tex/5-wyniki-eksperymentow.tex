\clearpage % Rozdziały zaczynamy od nowej strony.
\section{Wyniki eksperymentów}

% TODO tu skonczylem

W niniejszym rozdziale przedstawiono wyniki przeprowadzonych eksperymentów badających możliwości autonomicznego generowania konfiguracji Infrastructure as Code przez agenty oparte na dużych modelach językowych. Analiza wyników zorganizowana jest zgodnie ze strukturą hipotez badawczych przedstawionych w rozdziale 4 — dla każdej z pięciu hipotez (H1–H5) zaprezentowano wyniki eksperymentalne, analizę danych oraz wnioski dotyczące weryfikacji hipotezy. Rozdział kończy synteza wyników podkreślająca kluczowe obserwacje dotyczące zdolności LLM do generowania IaC.

\subsection{Przegląd przeprowadzonych eksperymentów}

Eksperymenty przeprowadzono zgodnie z metodologią opisaną w rozdziale 4, wykorzystując system orkiestracji umożliwiający automatyczne wykonanie serii testów dla różnych kombinacji modeli, repozytoriów i wariantów konfiguracji. Szczegóły zbiorów danych, środowiska wykonawczego oraz metryk znajdują się w rozdziale 4.

\subsection{Wyniki H1: Autonomiczna generacja funkcjonalnych konfiguracji}

\subsubsection{Hipoteza}

Duże modele językowe, działające jako agenty z dostępem do narzędzi analizy repozytorium, są w stanie autonomicznie wygenerować funkcjonalne konfiguracje Docker i Kubernetes, które umożliwiają poprawne uruchomienie aplikacji bez dodatkowej ingerencji człowieka.

\textbf{Zakres iteracji H1.0 (bazowej):} uruchomione z domyślnym promptem systemowym (\texttt{default.prompt}), trzema modelami (gemini-2.5-flash, gpt-5-mini, deepseek-chat), 2 powtórki na repo/model na 25 prostych aplikacjach webowych (lista w pliku konfiguracyjnym eksperymentu).

\subsubsection{Wyniki ilościowe}

% TODO: Tabela/wykres success rate per model + per etap (build/apply/runtime).

\textbf{Współczynnik sukcesu ogólny:}

% TODO: Wartość procentowa i krótki komentarz.

\textbf{Per etap (kaskada):}
\begin{itemize}
    \item Build: [X]\% sukcesu,
    \item K8s apply: [Y]\% sukcesu (z tych, które się zbudowały),
    \item Runtime (2xx na ingress): [Z]\% sukcesu (z tych, które się zaaplikowały).
\end{itemize}

\textbf{Rozbicie według języka programowania:}

% TODO: Tabela lub wykres.

\begin{itemize}
    \item Python: [X]\% sukcesu,
    \item Node.js: [Y]\% sukcesu,
    \item Go: [Z]\% sukcesu,
    \item Java: [W]\% sukcesu,
    \item Ruby: [V]\% sukcesu,
    \item Rust: [U]\% sukcesu.
\end{itemize}

\textbf{Rozbicie według frameworka:}

% TODO: Analiza dla popularnych frameworków.

\subsubsection{Analiza etapowa i warunkowa}

% TODO: Spadek skuteczności na etapach potoku (build -> apply -> runtime).

\subsubsection{Analiza przekrojowa (języki/frameworki)}

% TODO: Rozbicie skuteczności wg języka i frameworka.

\subsubsection{Typowe problemy i tryby awarii}

% TODO: Lista najczęstszych przyczyn niepowodzeń + przykłady.

\begin{itemize}
    \item \textbf{Błędna identyfikacja punktu wejścia aplikacji} — [X]\% przypadków,
    \item \textbf{Pominięcie zależności systemowych} — [Y]\% przypadków,
    \item \textbf{Niepoprawna konfiguracja zmiennych środowiskowych} — [Z]\% przypadków,
    \item \textbf{Błędy w definiowaniu portów i protokołów sieciowych} — [W]\% przypadków,
    \item \textbf{Brak obsługi inicjalizacji bazy danych} — [V]\% przypadków.
\end{itemize}

\subsubsection{Werdykt dla H1}

% TODO: Wniosek, czy H1 potwierdzona (z progami z rozdziału 4).

Na podstawie zgromadzonych danych można stwierdzić, że hipoteza H1 została [POTWIERDZONA/ODRZUCONA]. Współczynnik sukcesu [przekracza/nie osiąga] założony próg, co [wskazuje/nie wskazuje] na praktyczną przydatność podejścia agentowego do autonomicznego generowania konfiguracji IaC.

\subsection{Wyniki H2: Ograniczenia złożonościowe}

\subsubsection{Hipoteza}

% TODO: Wstaw treść hipotezy H2 (skrótowo).

\subsubsection{Wyniki ilościowe}

% TODO: Wykres success rate vs. poziom złożoności (repozytoria kontrolowane).

\subsubsection{Trend złożoności}

% TODO: Opis trendu spadku skuteczności i punktu załamania.

\subsubsection{Werdykt dla H2}

% TODO: Wniosek z odniesieniem do kryteriów z rozdziału 4.

\subsection{Wyniki H3: Jakość i zgodność z dobrymi praktykami}

\subsubsection{Hipoteza}

% TODO: Wstaw treść hipotezy H3 (skrótowo).

\subsubsection{Wyniki ilościowe}

% TODO: Liczba ostrzeżeń Hadolint/Kube-linter (bazowy prompt vs. prompt best practices).

\subsubsection{Wpływ prompt engineeringu}

% TODO: Porównanie jakości konfiguracji przed/po wzmocnieniu prompta.

\subsubsection{Werdykt dla H3}

% TODO: Wniosek z odniesieniem do progów z rozdziału 4.

\subsection{Wyniki H4: Niezawodność i powtarzalność procesu agentowego}

\subsubsection{Hipoteza}

% TODO: Wstaw treść hipotezy H4 (skrótowo).

\subsubsection{Wyniki ilościowe}

% TODO: run-to-run diff ratio + zmienność liczby kroków narzędziowych.

\subsubsection{Analiza powtarzalności}

% TODO: Wpływ deterministycznych parametrów (temperature=0, seed).

\subsubsection{Werdykt dla H4}

% TODO: Wniosek z odniesieniem do progów z rozdziału 4.

\subsection{Wyniki H5: Podatność na manipulację kontekstem}

\subsubsection{Hipoteza}

% TODO: Wstaw treść hipotezy H5 (skrótowo).

\subsubsection{Wyniki ilościowe}

% TODO: Odsetek przebiegów z odchyleniami od oczekiwań.

\subsubsection{Przykłady manipulacji}

% TODO: Krótkie studia przypadków (prompt injection, myląca dokumentacja).

\subsubsection{Werdykt dla H5}

% TODO: Wniosek z odniesieniem do progów z rozdziału 4.

\subsection{Porównanie modeli}

% TODO: Analiza przekrojowa modeli (skuteczność, jakość, powtarzalność).

\subsection{Synteza wyników}

\subsubsection{Podsumowanie weryfikacji hipotez}

% TODO: Tabela zbiorcza z werdyktem dla H1–H5 i krótkim uzasadnieniem.

\subsubsection{Kluczowe wnioski}

% TODO: 3–6 punktów najważniejszych obserwacji.

\subsubsection{Ograniczenia badania}

% TODO: Wypunktuj ograniczenia wyników (zbieżne z threats to validity).

\subsubsection{Implikacje praktyczne}

% TODO: Zalecenia dla praktyków i twórców narzędzi DevOps.
