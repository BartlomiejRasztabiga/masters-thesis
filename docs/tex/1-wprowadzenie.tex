\clearpage % Rozdziały zaczynamy od nowej strony.
\section{Wprowadzenie}

W ciągu ostatnich lat obserwujemy dynamiczny rozwój dużych modeli językowych (LLM) \cite{zhao_survey_2025} oraz równoległy wzrost znaczenia technologii konteneryzacji i orkiestracji. Modele takie jak GPT \cite{brown_language_2020}, LLaMA \cite{touvron_llama_2023}, Falcon \cite{almazrouei_falcon_2023} czy Claude \cite{anthropic_claude} wykazują zdolność generowania złożonego kodu, w tym konfiguracji infrastruktury \cite{srivatsa_survey_2024}, podczas gdy Docker \cite{merkel_docker_nodate} i Kubernetes \cite{burns_borg_2016} stały się standardami wdrażania aplikacji w środowiskach produkcyjnych \cite{kratzke_dont_2024}. Niniejsza praca bada potencjał wykorzystania dużych modeli językowych do pełnej automatyzacji procesu generowania i wdrażania konfiguracji Docker oraz Kubernetes, ze szczególnym uwzględnieniem aspektów poprawności, bezpieczeństwa oraz odporności na ataki manipulacyjne.

\subsection{Cel i zakres pracy}

Celem niniejszej pracy magisterskiej jest zbadanie możliwości autonomicznego generowania konfiguracji typu Infrastructure as Code (IaC, infrastruktura jako kod) \cite{pahl_infrastructure_nodate} przez agenty oparte na dużych modelach językowych (LLM), ze szczególnym uwzględnieniem plików Dockerfile oraz manifestów Kubernetes. Praca koncentruje się na weryfikacji, czy agenty LLM są w stanie — bez ingerencji człowieka — wygenerować funkcjonalne, bezpieczne i zgodne z dobrymi praktykami konfiguracje wdrożeniowe.

W ramach pracy zostanie przeprowadzona kompleksowa ocena funkcjonalności, jakości, bezpieczeństwa oraz niezawodności generowanych konfiguracji, ze szczególnym uwzględnieniem zagrożeń wynikających z automatyzacji, takich jak podatności na ataki typu "prompt injection" czy manipulację zawartością repozytoriów. Badanie oparte jest na weryfikacji pięciu hipotez badawczych (H1–H5) dotyczących: autonomicznej generacji funkcjonalnych konfiguracji, ograniczeń złożonościowych, jakości i zgodności z dobrymi praktykami, niezawodności procesu oraz podatności na manipulację kontekstem. [TODO: Na końcu pracy pokazano praktyczne zastosowanie wypracowanych rozwiązań w postaci prototypowego systemu typu Platform as a Service (PaaS).]

Praca ma charakter badawczo-eksperymentalny i obejmuje następujące zagadnienia:
\begin{itemize}
\item przegląd aktualnego stanu wiedzy na temat wykorzystania LLM w generowaniu kodu i konfiguracji infrastruktury,
\item identyfikację braków i zagrożeń związanych z automatyzacją generacji IaC, w tym problemów bezpieczeństwa i odporności na ataki (np. "prompt injection", manipulacja repozytorium),
\item sformułowanie i weryfikację hipotez badawczych dotyczących możliwości, ograniczeń oraz zagrożeń związanych z autonomicznym generowaniem konfiguracji IaC przez agenty LLM,
\item przeprowadzenie eksperymentów obejmujących testy funkcjonalności, złożoności, jakości, bezpieczeństwa, deterministyczności oraz odporności na manipulację,
\item wielowarstwową walidację jakości generowanych konfiguracji (automatyczna analiza statyczna, ocena przez model językowy, ocena ekspercka),
% \item TODO: zaprojektowanie i implementację prototypowego systemu typu PaaS demonstrującego praktyczne zastosowanie agentów LLM do automatycznego wdrażania aplikacji kontenerowych.
\end{itemize}

\subsection{Motywacja}

Motywacja pracy wynika z kilku kluczowych czynników. Po pierwsze, rośnie znaczenie metodyk DevOps oraz automatyzacji zarządzania infrastrukturą. IaC umożliwia spójną, powtarzalną konfigurację środowisk i redukcję błędów ludzkich \cite{low_repairing_2024}. Jednak ręczne tworzenie skryptów IaC dla złożonych środowisk chmurowych jest czasochłonne i wymaga specjalistycznej wiedzy. Rozwój dużych modeli językowych stwarza możliwość automatycznego generowania kodu konfiguracyjnego na podstawie opisów w języku naturalnym, co może obniżyć barierę wejścia dla mniej doświadczonych programistów i przyspieszyć procesy wdrożeniowe \cite{hu_llm-based_2025}.

Jednocześnie automatyzacja generowania IaC rodzi pytania o poprawność i bezpieczeństwo tworzonych konfiguracji. Modele językowe mogą popełniać błędy lub „halucynować”, generując nieistniejące lub niezalecane elementy konfiguracji \cite{malul_genkubesec_2024}. Istotne jest więc zbadanie wiarygodności LLM w kontekście infrastruktury krytycznej oraz zgodności generowanych plików z najlepszymi praktykami bezpieczeństwa. Automatyzacja tego procesu ma również praktyczne znaczenie w platformach typu PaaS, gdzie może znacząco skrócić czas wdrażania aplikacji oraz poprawić niezawodność i bezpieczeństwo świadczonych usług.

\subsection{Struktura pracy}

Praca składa się z następujących rozdziałów:
\begin{itemize}
    \item \textbf{Rozdział 1 – Wprowadzenie}: przedstawienie tematu, celów, motywacji oraz układu pracy,
    \item \textbf{Rozdział 2 – Przegląd literatury}: analiza aktualnych badań nad wykorzystaniem LLM w generowaniu konfiguracji IaC (Docker, Kubernetes) oraz identyfikacja luk w istniejącej wiedzy,
    \item \textbf{Rozdział 3 – Przegląd technologii i narzędzi}: opis wybranych modeli językowych, technologii infrastrukturalnych oraz architektury systemu agentowego,
    \item \textbf{Rozdział 4 – Projekt eksperymentów}: przedstawienie pięciu hipotez badawczych, metodyki ich weryfikacji, zestawów danych testowych, architektury systemu testowego oraz kryteriów oceny dla każdej hipotezy,
    \item \textbf{Rozdział 5 – Wyniki eksperymentów}: szczegółowa prezentacja wyników dla każdej z pięciu hipotez, analiza danych, wielowarstwowa walidacja jakości (automatyczna, LLM-as-a-Judge, ekspercka) oraz synteza wyników z wnioskami i implikacjami praktycznymi,
    % \item \textbf{[TODO: Rozdział 6 – Praktyczne zastosowanie – system PaaS]}: demonstracja praktycznego wykorzystania wypracowanych rozwiązań w postaci prototypowego systemu typu Platform as a Service automatyzującego wdrażanie aplikacji kontenerowych,
    \item \textbf{[TODO: Rozdział 7 – Wnioski i dalsze kierunki rozwoju]}: podsumowanie wyników badań, weryfikacja hipotez, ocena przydatności agentów LLM w kontekście DevOps oraz wskazanie możliwych obszarów dalszych badań.
\end{itemize}
